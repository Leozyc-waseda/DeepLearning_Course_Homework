{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# コンペティション課題4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題\n",
    "RNN Encoder-Decoderにより高精度な英日翻訳器を実装してみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目標値\n",
    "BLEU：0.23\n",
    "（これはあくまで「目標値」であるため、達成できなかったからといって不合格となったり、著しく成績が損なわれることはありません）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ルール\n",
    "- 「修正しないでください」とあるセルを、修正しないでください。\n",
    "- モデルのアーキテクチャは自由です。講義で扱ったモデル以外でも構いません。\n",
    "- 以下のセル内の`train_iter, val_iter`で定義されている`train, val`以外の学習データは使わないでください。\n",
    "- `id2text_en, id2text_ja`はIDをリストのindexとして入力することで、対応する単語を習得できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提出方法\n",
    "- 1つのファイルを提出していただきます。\n",
    "  1. テストデータ`test_iter`に対する予測ラベルを`submission4_gen.csv`として保存・ダウンロードしてください。\n",
    "  2. Homeworkタブから**Day4 Pred (.csv)**を選択して提出してください。\n",
    "  3. それとは別に、最終提出に対応するノートブックを[Final Submission]などと命名しわかるようにiLect System上に置いておいてください。\n",
    "- 成績優秀者には、次回講義にて取り組みの発表をお願いいたします。\n",
    "\n",
    "## LeaderBoard\n",
    "- コンペティション期間中のLeaderBoardは提出されたcsvファイルのうち50%を使って計算されます。\n",
    "- コンペティション終了時には提出されたcsvファイルのうち、コンペティション期間中のLeaderBoard計算に使われなかったもう半分のデータがスコア計算に使用されます。\n",
    "- このため、コンペ中の順位とコンペ終了後にLeaderBoardが更新された後の順位やスコアが食い違うことがあります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 評価方法\n",
    "\n",
    "- 予測ラベルの（`t_testに対する`）BLEUスコア(4-gramまで)で評価します。\n",
    "- BLEUスコア算出の際にはSmoothingを行っています。詳細は[こちらのmethod4](https://github.com/nltk/nltk/blob/7d6a8d42f6/nltk/translate/bleu_score.py#L577-L591)を確認してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの読み込み\n",
    "\n",
    "- このセルは修正しないでください。\n",
    "- 誤って修正した場合は、元ファイルをコピーし直してください。\n",
    "\n",
    "\n",
    "- データサイズが大きいため、読み込みには数分を要します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import torch\n",
    "from janome.tokenizer import Tokenizer\n",
    "from torchtext.data import Field, LabelField, TabularDataset, BucketIterator\n",
    "\n",
    "# 英語用のtokenizer\n",
    "spacy_en = spacy.load('en')\n",
    "def tokenizer_en(text):\n",
    "    return [token.text for token in spacy_en.tokenizer(text)]\n",
    "\n",
    "# 日本語用のtokenizer\n",
    "ja_t = Tokenizer()\n",
    "def tokenizer_ja(text): \n",
    "    return [token for token in ja_t.tokenize(text, wakati=True)]\n",
    "\n",
    "# 各Fieldを定義\n",
    "DATA_ID = LabelField(dtype=torch.int)\n",
    "SOURCE = Field(sequential=True, tokenize=tokenizer_en, init_token=\"<sos>\", eos_token=\"<eos>\", lower=True, include_lengths=True)\n",
    "TARGET = Field(sequential=True, tokenize=tokenizer_ja, init_token=\"<sos>\", eos_token=\"<eos>\", lower=False, include_lengths=True)\n",
    "\n",
    "train, val, test = TabularDataset.splits(\n",
    "    path=\"/root/userspace/public/day4/chap08/data\", \n",
    "    train=\"train.csv\", validation=\"val.csv\",\n",
    "    test=\"test_homework.csv\", format=\"csv\",\n",
    "    skip_header=True,\n",
    "    fields=[(\"data_id\", DATA_ID), (\"source\", SOURCE), (\"target\", TARGET)]\n",
    ")\n",
    "\n",
    "def load_dataset(batch_size, device):\n",
    "    # Vocabularyの作成\n",
    "    DATA_ID.build_vocab(train)\n",
    "    SOURCE.build_vocab(train, min_freq=2)\n",
    "    TARGET.build_vocab(train, min_freq=2)\n",
    "    id2text_en = SOURCE.vocab.itos\n",
    "    id2text_ja = TARGET.vocab.itos\n",
    "    \n",
    "    # 各種データセットのイテレータを作成\n",
    "    train_iter, val_iter, test_iter = BucketIterator.splits(\n",
    "    (train, val, test), batch_size=batch_size, device=device, sort=False)\n",
    "    \n",
    "    return train_iter, val_iter, test_iter, SOURCE, TARGET, id2text_en, id2text_ja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#精度上げるポイント\n",
    "1. https://github.com/bentrevett/pytorch-seq2seq ドイツ→英語のレポジトリを参考しつつ，　実装した\n",
    "2. tokenizerの変更"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import torch\n",
    "from janome.tokenizer import Tokenizer\n",
    "from torchtext.data import Field, LabelField, TabularDataset, BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install spaCy==3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python3 -m spacy download ja_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# 英語用のtokenizer\n",
    "spacy_en = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "def tokenizer_en(text):\n",
    "    return [token for token in spacy_en.tokenize(text)]\n",
    "\n",
    "# 日本語用のtokenizer\n",
    "ja_t = spacy.load('ja_core_news_lg')\n",
    "def tokenizer_ja(text): \n",
    "    return [token.text for token in ja_t.tokenizer(text)]\n",
    "\n",
    "SRC = Field(tokenize = tokenizer_en, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True, \n",
    "            batch_first = True)\n",
    "\n",
    "TRG = Field(tokenize = tokenizer_ja, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True, \n",
    "            batch_first = True)\n",
    "DATA_ID = LabelField(dtype=torch.int)\n",
    "\n",
    "train_data, valid_data, test_data = TabularDataset.splits(\n",
    "    path=\"/root/userspace/public/day4/chap08/data\", \n",
    "    train=\"train.csv\", validation=\"val.csv\",\n",
    "    test=\"test_homework.csv\", format=\"csv\",\n",
    "    skip_header=True,\n",
    "     fields=[(\"data_id\", DATA_ID), (\"source\", SRC), (\"target\", TRG)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 35000\n",
      "Number of validation examples: 7500\n",
      "Number of testing examples: 7500\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_id': '0', 'source': ['i', 'can', \"'\", 't', 'tell', 'who', 'will', 'arrive', 'first', '.'], 'target': ['誰', 'が', '一番', 'に', '着く', 'か', '私', 'に', 'は', '分かり', 'ませ', 'ん', '。']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 2)\n",
    "TRG.build_vocab(train_data, min_freq = 2)\n",
    "DATA_ID.build_vocab(train_data)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (JA) vocabulary: 3748\n",
      "Unique tokens in target (en) vocabulary: 4848\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in source (JA) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "     batch_size = BATCH_SIZE,\n",
    "     device = device,\n",
    "     sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import spacy\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 hid_dim, \n",
    "                 n_layers, \n",
    "                 n_heads, \n",
    "                 pf_dim,\n",
    "                 dropout, \n",
    "                 device,\n",
    "                 max_length = 100):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "        \n",
    "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
    "        \n",
    "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, \n",
    "                                                  n_heads, \n",
    "                                                  pf_dim,\n",
    "                                                  dropout, \n",
    "                                                  device) \n",
    "                                     for _ in range(n_layers)])\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
    "        \n",
    "    def forward(self, src, src_mask):\n",
    "        \n",
    "        #src = [batch size, src len]\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "        \n",
    "        batch_size = src.shape[0]\n",
    "        src_len = src.shape[1]\n",
    "        \n",
    "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
    "        \n",
    "        #pos = [batch size, src len]\n",
    "        \n",
    "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
    "        \n",
    "        #src = [batch size, src len, hid dim]\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            src = layer(src, src_mask)\n",
    "            \n",
    "        #src = [batch size, src len, hid dim]\n",
    "            \n",
    "        return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 hid_dim, \n",
    "                 n_heads, \n",
    "                 pf_dim,  \n",
    "                 dropout, \n",
    "                 device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
    "                                                                     pf_dim, \n",
    "                                                                     dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src, src_mask):\n",
    "        \n",
    "        #src = [batch size, src len, hid dim]\n",
    "        #src_mask = [batch size, 1, 1, src len] \n",
    "                \n",
    "        #self attention\n",
    "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
    "        \n",
    "        #dropout, residual connection and layer norm\n",
    "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
    "        \n",
    "        #src = [batch size, src len, hid dim]\n",
    "        \n",
    "        #positionwise feedforward\n",
    "        _src = self.positionwise_feedforward(src)\n",
    "        \n",
    "        #dropout, residual and layer norm\n",
    "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
    "        \n",
    "        #src = [batch size, src len, hid dim]\n",
    "        \n",
    "        return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert hid_dim % n_heads == 0\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = hid_dim // n_heads\n",
    "        \n",
    "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
    "        \n",
    "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
    "        \n",
    "    def forward(self, query, key, value, mask = None):\n",
    "        \n",
    "        batch_size = query.shape[0]\n",
    "        \n",
    "        #query = [batch size, query len, hid dim]\n",
    "        #key = [batch size, key len, hid dim]\n",
    "        #value = [batch size, value len, hid dim]\n",
    "                \n",
    "        Q = self.fc_q(query)\n",
    "        K = self.fc_k(key)\n",
    "        V = self.fc_v(value)\n",
    "        \n",
    "        #Q = [batch size, query len, hid dim]\n",
    "        #K = [batch size, key len, hid dim]\n",
    "        #V = [batch size, value len, hid dim]\n",
    "                \n",
    "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        \n",
    "        #Q = [batch size, n heads, query len, head dim]\n",
    "        #K = [batch size, n heads, key len, head dim]\n",
    "        #V = [batch size, n heads, value len, head dim]\n",
    "                \n",
    "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
    "        \n",
    "        #energy = [batch size, n heads, query len, key len]\n",
    "        \n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, -1e10)\n",
    "        \n",
    "        attention = torch.softmax(energy, dim = -1)\n",
    "                \n",
    "        #attention = [batch size, n heads, query len, key len]\n",
    "                \n",
    "        x = torch.matmul(self.dropout(attention), V)\n",
    "        \n",
    "        #x = [batch size, n heads, query len, head dim]\n",
    "        \n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        \n",
    "        #x = [batch size, query len, n heads, head dim]\n",
    "        \n",
    "        x = x.view(batch_size, -1, self.hid_dim)\n",
    "        \n",
    "        #x = [batch size, query len, hid dim]\n",
    "        \n",
    "        x = self.fc_o(x)\n",
    "        \n",
    "        #x = [batch size, query len, hid dim]\n",
    "        \n",
    "        return x, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedforwardLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, pf_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
    "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #x = [batch size, seq len, hid dim]\n",
    "        \n",
    "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
    "        \n",
    "        #x = [batch size, seq len, pf dim]\n",
    "        \n",
    "        x = self.fc_2(x)\n",
    "        \n",
    "        #x = [batch size, seq len, hid dim]\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 output_dim, \n",
    "                 hid_dim, \n",
    "                 n_layers, \n",
    "                 n_heads, \n",
    "                 pf_dim, \n",
    "                 dropout, \n",
    "                 device,\n",
    "                 max_length = 100):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
    "        \n",
    "        self.layers = nn.ModuleList([DecoderLayer(hid_dim, \n",
    "                                                  n_heads, \n",
    "                                                  pf_dim, \n",
    "                                                  dropout, \n",
    "                                                  device)\n",
    "                                     for _ in range(n_layers)])\n",
    "        \n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
    "        \n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "        \n",
    "        #trg = [batch size, trg len]\n",
    "        #enc_src = [batch size, src len, hid dim]\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "                \n",
    "        batch_size = trg.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        \n",
    "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
    "                            \n",
    "        #pos = [batch size, trg len]\n",
    "            \n",
    "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
    "                \n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
    "        \n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "        #attention = [batch size, n heads, trg len, src len]\n",
    "        \n",
    "        output = self.fc_out(trg)\n",
    "        \n",
    "        #output = [batch size, trg len, output dim]\n",
    "            \n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 hid_dim, \n",
    "                 n_heads, \n",
    "                 pf_dim, \n",
    "                 dropout, \n",
    "                 device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
    "                                                                     pf_dim, \n",
    "                                                                     dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "        \n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "        #enc_src = [batch size, src len, hid dim]\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "        \n",
    "        #self attention\n",
    "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
    "        \n",
    "        #dropout, residual connection and layer norm\n",
    "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
    "            \n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "            \n",
    "        #encoder attention\n",
    "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
    "        \n",
    "        #dropout, residual connection and layer norm\n",
    "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
    "                    \n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "        \n",
    "        #positionwise feedforward\n",
    "        _trg = self.positionwise_feedforward(trg)\n",
    "        \n",
    "        #dropout, residual and layer norm\n",
    "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
    "        \n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "        #attention = [batch size, n heads, trg len, src len]\n",
    "        \n",
    "        return trg, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, \n",
    "                 encoder, \n",
    "                 decoder, \n",
    "                 src_pad_idx, \n",
    "                 trg_pad_idx, \n",
    "                 device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "        self.device = device\n",
    "        \n",
    "    def make_src_mask(self, src):\n",
    "        \n",
    "        #src = [batch size, src len]\n",
    "        \n",
    "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "\n",
    "        return src_mask\n",
    "    \n",
    "    def make_trg_mask(self, trg):\n",
    "        \n",
    "        #trg = [batch size, trg len]\n",
    "        \n",
    "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        \n",
    "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
    "        \n",
    "        trg_len = trg.shape[1]\n",
    "        \n",
    "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
    "        \n",
    "        #trg_sub_mask = [trg len, trg len]\n",
    "            \n",
    "        trg_mask = trg_pad_mask & trg_sub_mask\n",
    "        \n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        \n",
    "        return trg_mask\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        \n",
    "        #src = [batch size, src len]\n",
    "        #trg = [batch size, trg len]\n",
    "                \n",
    "        src_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "        \n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        \n",
    "        enc_src = self.encoder(src, src_mask)\n",
    "        \n",
    "        #enc_src = [batch size, src len, hid dim]\n",
    "                \n",
    "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
    "        \n",
    "        #output = [batch size, trg len, output dim]\n",
    "        #attention = [batch size, n heads, trg len, src len]\n",
    "        \n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "HID_DIM = 256\n",
    "ENC_LAYERS = 3\n",
    "DEC_LAYERS = 3\n",
    "ENC_HEADS = 8\n",
    "DEC_HEADS = 8\n",
    "ENC_PF_DIM = 512\n",
    "DEC_PF_DIM = 512\n",
    "ENC_DROPOUT = 0.1\n",
    "DEC_DROPOUT = 0.1\n",
    "\n",
    "enc = Encoder(INPUT_DIM, \n",
    "              HID_DIM, \n",
    "              ENC_LAYERS, \n",
    "              ENC_HEADS, \n",
    "              ENC_PF_DIM, \n",
    "              ENC_DROPOUT, \n",
    "              device)\n",
    "\n",
    "dec = Decoder(OUTPUT_DIM, \n",
    "              HID_DIM, \n",
    "              DEC_LAYERS, \n",
    "              DEC_HEADS, \n",
    "              DEC_PF_DIM, \n",
    "              DEC_DROPOUT, \n",
    "              device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "\n",
    "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 7,451,376 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "        \n",
    "model.apply(initialize_weights);\n",
    "\n",
    "LEARNING_RATE = 0.0005\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        src = batch.source\n",
    "        trg = batch.target\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output, _ = model(src, trg[:,:-1])\n",
    "                \n",
    "        #output = [batch size, trg len - 1, output dim]\n",
    "        #trg = [batch size, trg len]\n",
    "            \n",
    "        output_dim = output.shape[-1]\n",
    "            \n",
    "        output = output.contiguous().view(-1, output_dim)\n",
    "        trg = trg[:,1:].contiguous().view(-1)\n",
    "                \n",
    "        #output = [batch size * trg len - 1, output dim]\n",
    "        #trg = [batch size * trg len - 1]\n",
    "            \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            src = batch.source\n",
    "            trg = batch.target\n",
    "\n",
    "            output, _ = model(src, trg[:,:-1])\n",
    "            \n",
    "            #output = [batch size, trg len - 1, output dim]\n",
    "            #trg = [batch size, trg len]\n",
    "            \n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            trg = trg[:,1:].contiguous().view(-1)\n",
    "            \n",
    "            #output = [batch size * trg len - 1, output dim]\n",
    "            #trg = [batch size * trg len - 1]\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 33s\n",
      "\tTrain Loss: 1.045 \n",
      "\t Val. Loss: 1.607 \n",
      "Epoch: 02 | Time: 0m 33s\n",
      "\tTrain Loss: 0.961 \n",
      "\t Val. Loss: 1.613 \n",
      "Epoch: 03 | Time: 0m 33s\n",
      "\tTrain Loss: 0.891 \n",
      "\t Val. Loss: 1.610 \n",
      "Epoch: 04 | Time: 0m 33s\n",
      "\tTrain Loss: 0.829 \n",
      "\t Val. Loss: 1.644 \n",
      "Epoch: 05 | Time: 0m 33s\n",
      "\tTrain Loss: 0.776 \n",
      "\t Val. Loss: 1.634 \n",
      "Epoch: 06 | Time: 0m 33s\n",
      "\tTrain Loss: 0.730 \n",
      "\t Val. Loss: 1.647 \n",
      "Epoch: 07 | Time: 0m 33s\n",
      "\tTrain Loss: 0.687 \n",
      "\t Val. Loss: 1.675 \n",
      "Epoch: 08 | Time: 0m 33s\n",
      "\tTrain Loss: 0.651 \n",
      "\t Val. Loss: 1.695 \n",
      "Epoch: 09 | Time: 0m 33s\n",
      "\tTrain Loss: 0.615 \n",
      "\t Val. Loss: 1.718 \n",
      "Epoch: 10 | Time: 0m 32s\n",
      "\tTrain Loss: 0.587 \n",
      "\t Val. Loss: 1.744 \n",
      "Epoch: 11 | Time: 0m 33s\n",
      "\tTrain Loss: 0.559 \n",
      "\t Val. Loss: 1.768 \n",
      "Epoch: 12 | Time: 0m 33s\n",
      "\tTrain Loss: 0.533 \n",
      "\t Val. Loss: 1.788 \n",
      "Epoch: 13 | Time: 0m 33s\n",
      "\tTrain Loss: 0.511 \n",
      "\t Val. Loss: 1.820 \n",
      "Epoch: 14 | Time: 0m 33s\n",
      "\tTrain Loss: 0.490 \n",
      "\t Val. Loss: 1.837 \n",
      "Epoch: 15 | Time: 0m 33s\n",
      "\tTrain Loss: 0.470 \n",
      "\t Val. Loss: 1.863 \n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 15\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), '/root/userspace/day4/homework4/tut6-model1.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} ')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 9.443 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('/root/userspace/day4/homework4/tut6-model1.pt'))\n",
    "\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
    "    \n",
    "    model.eval()\n",
    "        \n",
    "    if isinstance(sentence, str):\n",
    "        nlp = spacy.load('ja_core_news_lg')\n",
    "        \n",
    "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
    "        \n",
    "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
    "\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
    "    \n",
    "    src_mask = model.make_src_mask(src_tensor)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        enc_src = model.encoder(src_tensor, src_mask)\n",
    "\n",
    "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
    "\n",
    "    for i in range(max_len):\n",
    "\n",
    "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
    "\n",
    "        trg_mask = model.make_trg_mask(trg_tensor)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
    "        \n",
    "        pred_token = output.argmax(2)[:,-1].item()\n",
    "        \n",
    "        trg_indexes.append(pred_token)\n",
    "\n",
    "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
    "            break\n",
    "    \n",
    "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
    "    \n",
    "    return trg_tokens[1:], attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src = ['they', 'are', 'very', 'compatible', '.']\n",
      "trg = ['彼', 'ら', '二人', 'は', 'よく', '肌', 'が', '合う', '。']\n",
      "predicted trg = ['彼', 'ら', 'は', 'とても', '<unk>', 'です', '。', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "example_idx = 5\n",
    "src = vars(valid_data.examples[example_idx])['source']\n",
    "trg = vars(valid_data.examples[example_idx])['target']\n",
    "print(f'src = {src}')\n",
    "print(f'trg = {trg}')\n",
    "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
    "\n",
    "print(f'predicted trg = {translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id_pred = []\n",
    "for batch in test_iterator:\n",
    "    data_id_pred += [int(DATA_ID.vocab.itos[i]) for i in batch.data_id.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save prediction output to y_pred\n",
    "y_pred = []\n",
    "for idx in range(len(test_data.examples)):\n",
    "    src = vars(test_data.examples[idx])['source']\n",
    "    translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
    "    y_pred.append(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "outputs = \" \"\n",
    "output = []\n",
    "i=0\n",
    "for number in y_pred:\n",
    "    maxlen=0\n",
    "    #print(texts)\n",
    "    for k in number:\n",
    "        maxlen+=1\n",
    "        if k !='<eos>'and maxlen<=40 :\n",
    "            texts.append(k)\n",
    "        elif maxlen<42:\n",
    "            outputs = [' '.join(texts)]\n",
    "            i+=1\n",
    "            texts = [ ] \n",
    "            output +=outputs\n",
    "#         elif maxlen>=51:\n",
    "#             outputs = [' '.join(texts)]\n",
    "#             texts = [ ] \n",
    "#             i+=1\n",
    "#             output +=outputs\n",
    "    #print(maxlen)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['雨 が やん で 待とう 。',\n",
       " 'あなた は 酒 を 飲む べき だ 。',\n",
       " '君 は 一 晩 中 食事 を 変え ませ ん か 。',\n",
       " 'この 学校 は この 川 の <unk> です か 。',\n",
       " '彼 ら は その 仕事 を 終え て しまっ た 。',\n",
       " '私 に は お 金 の 持ち合わせ が ない 。',\n",
       " '私 は 彼 の 結婚 し た 生活 を <unk> た 。',\n",
       " '私 たち は 車 で 車 を 運転 し た 。',\n",
       " '私 は 若い 頃 、 山 に 山 に 行き たい 。',\n",
       " 'あの 人 は あの 我慢 でき ない 。',\n",
       " '君 は そんな に 遅く まで 起き て い た 方 が よい 。',\n",
       " '私 は まだ 手 に いくら 持っ て い ます 。',\n",
       " '私 は この 家 に 帰っ て くる 。',\n",
       " '彼 は 私 に その 仕事 を <unk> た 。',\n",
       " '馬鹿 な 馬鹿 で は ない で 。',\n",
       " '男 は とても 素敵 だ 。',\n",
       " '暗闇 で は なく て 人生 を 見 て は いけ ない 。',\n",
       " '多く の 人々 が 日本 を 訪れ た 。',\n",
       " '彼女 は パーティー に 出席 し たい 。',\n",
       " 'この 語 は 使い 出し た 。',\n",
       " 'この 博物 館 へ 行く 道 は どう です か 。',\n",
       " '彼女 は 彼 ら に とても とても とても <unk> し た 。',\n",
       " 'できる だけ 早く 起き なさい 。',\n",
       " '私 は どこ へ 行っ て も 行き ませ ん 。',\n",
       " '彼 は 東京 から パリ へ 出発 し た 。',\n",
       " '私 は それ に つい て 知り ませ ん 。',\n",
       " '金 は 少し しか なく なっ た 。',\n",
       " 'あなた に 会う の を 楽し み に し て い まし た 。',\n",
       " '彼 ら は 彼女 に <unk> 会っ た 。',\n",
       " '私 は 来月 散髪 する 。',\n",
       " '私 に は ２人 の 娘 が いる 。',\n",
       " '明日 の 朝 電話 を かけ ます 。',\n",
       " 'ジョン は 門 を 門 の 楽し み に し て き た 。',\n",
       " 'それ は どの くらい の 高 さ です か 。',\n",
       " '君 は 一日 から 休み ます か 。',\n",
       " '彼 は 気 に <unk> し た 。',\n",
       " '彼 は その 家 を 引き 継い だ 。',\n",
       " '君 は 皆 に やっ て おい て ください 。',\n",
       " '君 は 同じ こと に し て いる 。',\n",
       " 'それ は 何 から し た の です か 。',\n",
       " '私 は 今週 休み です 。',\n",
       " '私 たち は 彼女 の 健康 を 心配 し て いる 。',\n",
       " '私 は とても 疲れ て い た の で 早く 寝 た 。',\n",
       " '彼 は 仕事 で <unk> し なかっ た 。',\n",
       " '彼 ら は 明日 結婚 する つもり だ 。',\n",
       " 'たいてい の 人々 は テレビ を 見 て いる 。',\n",
       " '日本 は 平和 と 彼女 の 平和 に ある 。',\n",
       " '彼 の 車 は 列車 に ぶつかっ た 。',\n",
       " '伝言 を お 願い し ます か 。',\n",
       " '君 が 私 の 部屋 に 入っ て き た 。',\n",
       " 'あまり あまり あまり に <unk> な 。',\n",
       " '彼女 は 外出 し て いる 。',\n",
       " '彼女 は 田舎 に 住ん で いる 。',\n",
       " '彼女 は 一人 で 何 も うまく いく こと は でき ない 。',\n",
       " '彼 は 私 の 妹 に 似 て いる よう だ 。',\n",
       " 'あなた が 出 かける と すぐ に い ます 。',\n",
       " '彼女 は 自分 の 約束 を <unk> て いる 。',\n",
       " '彼 は 若い ころ は 自分 の ため に 失敗 し た 。',\n",
       " '彼 は そこ へ 行っ た 人 が い た 。',\n",
       " '<unk> が ひどい の で 寒かっ た 。',\n",
       " 'それ は 一 日 中 雪 が 降っ て い た 。',\n",
       " 'すぐ 雨 が 降り そう だ 。',\n",
       " 'ドア の 中 に 誰 が 入っ て いる の です か 。',\n",
       " '私 は この 仕事 前 に <unk> 始め た 。',\n",
       " '私 は 今晩 仕事 を する こと が ある 。',\n",
       " '私 は ケン に 公園 で 会っ た 。',\n",
       " '誰 も 彼 に は <unk> ない 。',\n",
       " 'お 手伝い し て くださる なら ご 親切 に お 手伝い ください 。',\n",
       " '私 は その 質問 に 答える こと が でき た 。',\n",
       " '私 は どう し て よい か 知っ て い ます か 。',\n",
       " 'もう もう 寝る 時間 です 。',\n",
       " '彼 ら は 毎日 その 日 に 払っ て いる 。',\n",
       " '私 は 彼 に 私 の 車 を どこ に 連れ て いっ た 。',\n",
       " 'あなた に 秘密 を 話し ます 。',\n",
       " 'その 薬 は 彼女 の 命 を 得 た 。',\n",
       " 'どこ へ 行く べき です か 。',\n",
       " '私 は 彼 に <unk> を 作っ た 。',\n",
       " '彼 は この 仕事 を <unk> する 。',\n",
       " '私 は 彼 に 何 も 知ら ない 。',\n",
       " '私 は 最近 ずっと 忙しい 。',\n",
       " '私 の 姉 は 音楽 が 好き です 。',\n",
       " '私 の おかげ で 成功 する の は 君 の おかげ です 。',\n",
       " '私 は 早く 起き た 。',\n",
       " '自分 の 国 を 愛さ ない 人 は い ない 。',\n",
       " 'あなた の 命 を 教え て あげよう 。',\n",
       " '彼 は 彼女 の 成功 を 幸せ に し て い た 。',\n",
       " '彼 は 一目 で 彼女 に 恋 を し た 。',\n",
       " '私 たち は 彼 に スピーチ を 呼ん で しまっ た 。',\n",
       " '彼 から まだ 何 の 話 も 聞い て い ない 。',\n",
       " '彼 は 彼女 に きっと 腹 を 立て て いる 。',\n",
       " 'この 時計 は 防水 に なっ て いる 。',\n",
       " 'たいてい の 少年 は 彼 の 名前 を 知っ て いる 。',\n",
       " 'あなた は どこ に いる の です か 。',\n",
       " '散歩 に 行き ませ ん か 。',\n",
       " '東京 は 私 に は 賛成 し ない 。',\n",
       " 'りんご が とても 上手 に 木 を かけ なさい 。',\n",
       " '何 と 残念 な こと でしょう 。',\n",
       " 'あなた は この 辞書 を 自由 に 使っ て ください 。',\n",
       " '彼 は 必ず それ を 払わ ない でしょう 。',\n",
       " '一番 好き な <unk> は どの よう に 好き です か 。',\n",
       " 'その 家 に は 誰 も い なかっ た 。',\n",
       " '彼 は 私 たち の 問題 に 答え て き た 。',\n",
       " '彼 は 一目 で 彼女 に 恋 を し た 。',\n",
       " 'その 猫 は 眠っ て いる 。',\n",
       " '彼 ら は すぐ に お 互い に 慣れ た 。',\n",
       " '息子 は 息子 から 父親 に いたずら し た 。',\n",
       " '彼女 は 息子 に たくさん お 金 を 持っ て いる 。',\n",
       " 'すぐ 出発 し た 方 が よい 。',\n",
       " '彼 は 何 も し なかっ た 。',\n",
       " '私 たち は 何 を 話し て い た の です か 。',\n",
       " '夏 は すぐ に <unk> 。',\n",
       " '何 が 起こる か はっきり し て も わから ない 。',\n",
       " '月 が 今夜 空 に <unk> て いる 。',\n",
       " '彼 に 電話 を かけ て ください 。',\n",
       " '母 は 今 とても 忙しい 。',\n",
       " '今朝 は 早く 起き た 。',\n",
       " '彼女 が 長い こと 待た ない うち に 現れ た 。',\n",
       " 'この 本 は とても 面白い 。',\n",
       " '老人 が 一番 やさしい の は 楽しい 。',\n",
       " '私 は 音楽 が 好き です 。',\n",
       " '忠告 に 感謝 し て ありがとう 。',\n",
       " '食事 前 に は <unk> を し なさい 。',\n",
       " '本当 に 風 が 吹い た 。',\n",
       " '私 は 早く そこ に 着い た 。',\n",
       " '私 は 彼 ら の どちら も 好き で は ない 。',\n",
       " '電話 中 に 電話 を かけ て 、 私 は 仕事 が でき ます 。',\n",
       " '彼 は 今 風邪 を ひい て いる 。',\n",
       " '私 は お 金 が 足り ない 。',\n",
       " '彼女 は 仕事 を 辞める べき だ 。',\n",
       " 'あなた に お 幸せ な こと を 知っ て い ます 。',\n",
       " '彼 は 大 家族 を 養わ なけれ ば なら ない 。',\n",
       " '私 は イタリア へ 行く つもり だ 。',\n",
       " '明日 は あなた に 会い ましょう 。',\n",
       " 'あなた の お 父さん に よろしく 。',\n",
       " 'それ は 申し分 ない です 。',\n",
       " '好き な だけ 取り なさい 。',\n",
       " 'その ニュース は ちょうど ラジオ で ちょうど ちょうど ちょうど やっ て き た 。',\n",
       " '彼 は どんな こと で も する はず が ない 。',\n",
       " '彼女 は 幸せ だっ た らしい 。',\n",
       " '彼 は 明日 電話 を かけ て くれ ませ ん か 。',\n",
       " 'ちょっと お 願い し ませ ん か 。',\n",
       " 'こんな に 待た せ て ごめん なさい 。',\n",
       " '彼 は 赤い 車 に 決め た 。',\n",
       " '日本 は 難しい 日 に 立ち 上がっ た 。',\n",
       " '彼 は 本 を 読む より も 読める 。',\n",
       " 'その 少年 は <unk> が うまい 。',\n",
       " '彼女 は 弟 の 手紙 を <unk> で 彼女 は 出 かけ た 。',\n",
       " '彼女 は いい 考え だ と 思う 。',\n",
       " 'メアリー は 昨夜 遅く まで 起き て い た 。',\n",
       " 'あなた の 名前 は どう つづる の です か 。',\n",
       " '彼女 は たった 今 帰宅 し た ところ だ 。',\n",
       " '父 は ９ 年 の 年 に 年 を <unk> た 。',\n",
       " '２ 階 へ 寝 なさい 。',\n",
       " '彼女 は 近く に 走り ながら 走っ た 。',\n",
       " '私 は その ニュース に とても 驚い た 。',\n",
       " 'あなた から 便り が あり まし た 。',\n",
       " '老人 に 親切 に し なさい 。',\n",
       " '彼女 は コンサート の 切符 を <unk> た 。',\n",
       " 'あの 時計 は すぐ に 速く ます 。',\n",
       " 'あなた の 報告 書 を 呼び 出し て くれ まし た か 。',\n",
       " '彼女 は 静か に し て い ます 。',\n",
       " '彼女 は その 子供 の 食べ物 を 食べ物 に 食べる よう に 言っ た 。',\n",
       " '彼 ら は 話し 掛け た 。',\n",
       " '私 は ２ 年間 ずっと 勉強 し て い ます 。',\n",
       " '<unk> も 来る か も しれ ない 。',\n",
       " '学生 に は <unk> が なかっ た 。',\n",
       " 'あなた は 両親 に よろしく お 伝え ください まし た か 。',\n",
       " 'これ は 日本 の <unk> です 。',\n",
       " '地球 は 丸い だ 。',\n",
       " '私 は その 時 家 に い まし た 。',\n",
       " '私 は 彼 と 英語 だけ の 話せ ない 。',\n",
       " '彼 は １万 ドル 払っ た 。',\n",
       " 'すぐ に 彼女 に 手紙 を 書く の は 難しい 。',\n",
       " 'あなた は 本当 に 愛し て い ます か 。',\n",
       " '彼 ら は 東京 へ 来 て から そこ へ 来 た 。',\n",
       " '私 は 終電 に 遅れ た 。',\n",
       " '彼 ら は ついに 見え なく 見え なく なっ た 。',\n",
       " 'その 仕事 は 結局 結局 うまく やっ て き た 。',\n",
       " 'その 件 に 関し て 君 に 賛成 でき ない 。',\n",
       " '彼 に 来る と 思い ます 。',\n",
       " 'この 手紙 を 書き ましょう か 。',\n",
       " '彼女 は 英語 を 上手 に 英語 を 話せ ます 。',\n",
       " '彼 の 話 は 誤り で ある と わかっ た 。',\n",
       " '私 は 朝 早く 散歩 する の に 慣れ た もの だっ た 。',\n",
       " '別 の こと を 考え て みよう 。',\n",
       " '私 の 部屋 に ３ 分 の 中 に 来 なさい 。',\n",
       " '君 は 親切 に も 私 に も くれ ない 。',\n",
       " '今夜 は 月 に 見 られ て も いい 。',\n",
       " '世界 で 戦争 が あり ませ ん 。',\n",
       " 'その 店 は ちょうど 駅 の 前 に ある 。',\n",
       " '車 を <unk> なさい 。',\n",
       " '両親 の 趣味 に 従っ て 行動 を 取り なさい 。',\n",
       " '彼 は 私 と 同じ くらい 速く 走る こと が でき ない 。',\n",
       " 'あなた に 一度 それ を 教え て あげよう 。',\n",
       " 'コート を 着 て いただけ ませ ん か 。',\n",
       " '彼女 は 何 と 言っ た の だろう 。',\n",
       " '私 の 夢 は 医者 です 。',\n",
       " '彼 は 年 の 割 に は 合わ ない 。',\n",
       " '明日 は 泳ぎ に 行き ます 。',\n",
       " 'あなた に 会う の を 楽し み に し て い ます 。',\n",
       " '耳 に お 聞き ください ませ ん か 。',\n",
       " '彼 は 君 の 間違っ て いる 。',\n",
       " '６ 月 に 待つ こと は また 終わり ます 。',\n",
       " '彼女 は 全く 怒っ て いる 。',\n",
       " 'この 書類 を もう <unk> て いただけ ませ ん か 。',\n",
       " 'それ は あまり 難しい 。',\n",
       " '道 を 教え て ください 。',\n",
       " 'もう ６ 時 です 。',\n",
       " '出席 し た の は どう だっ た の です か 。',\n",
       " 'この 問題 は 私 に は この 問題 が かかっ て いる 。',\n",
       " '君 は 最善 を 尽くし さえ すれ ば よい 。',\n",
       " '彼 は テーブル に 口 に <unk> を 話し た 。',\n",
       " '私 は もう これ 以上 歩け ない 。',\n",
       " '教室 で 食べ ます 。',\n",
       " '明日 は 晴れる と 思い ます か 。',\n",
       " 'もう 少し 静か に し て 下さい 。',\n",
       " 'その 道 は 修理 中 です 。',\n",
       " '彼女 は 旅行 の 準備 に 忙しい 。',\n",
       " '彼 は まだ 若い 。',\n",
       " '私 は 時間 を 無駄 に し て 時間 を 見 た 。',\n",
       " 'その 息子 は 父親 に よっ て 知ら れ て いる 。',\n",
       " '新しい 家 に 建て られ ます 。',\n",
       " '車 は あなた の 中 です 。',\n",
       " '彼女 は 結局 来 なかっ た 。',\n",
       " '<unk> さん 、 ここ に 学校 の 近い の です か 。',\n",
       " '彼女 は 何 か 好き な こと が ある か も しれ ない 。',\n",
       " 'この <unk> は 決して <unk> ない 。',\n",
       " '彼 は ５ 冊 以上 の 本 を 持っ て いる 。',\n",
       " 'あの 女の子 は 誰 です か 。',\n",
       " '今日 は この 寒 さ が ちょうど 寒い の に ある 。',\n",
       " '道 を 知ら せ て ください 。',\n",
       " '<unk> が 起こる か は <unk> た 。',\n",
       " '私 は あなた の 趣味 に つい て い ます 。',\n",
       " 'その 仕事 は まだ 終わっ て いる 。',\n",
       " '我々 は すぐ 出発 し 始め た 。',\n",
       " '彼女 に 仕事 が 必要 で は ない 。',\n",
       " '昼食 は <unk> し た 。',\n",
       " 'それ は 全く 私 に は 全く 知ら ない 。',\n",
       " '私 は 昼食 も 食べ て い ない 。',\n",
       " '健康 は 大切 な こと で ある 。',\n",
       " '私 は 彼女 に 何 か 何 で も する 。',\n",
       " 'これ が メアリー の 絵 です 。',\n",
       " '彼 は どこ から 来 た の で は なかっ た 。',\n",
       " 'ここ で 何 を し て いる の です か 。',\n",
       " '彼 は アメリカ 人 で は ない の です か 。',\n",
       " '誰 か そこ に い まし た か 。',\n",
       " '今日 は 幸せ そう です ね 。',\n",
       " '彼女 は 若い ころ 美しかっ た に 違い ない 。',\n",
       " 'パーティー に は いつ か どう か 決め ましょう か 。',\n",
       " 'よく 釣り に 行く の は よく 考え だ 。',\n",
       " 'ある こと は 元 通り に し て は いけ ない 。',\n",
       " '彼 は すぐ 戻っ て き ます 。',\n",
       " '私 は あなた の 手紙 を 楽し み に し て い ます 。',\n",
       " '彼女 は とても 美しい 。',\n",
       " '私 たち は 遠く に 明かり を 見 た 。',\n",
       " '彼 は <unk> だ 。',\n",
       " '彼 は ５ 年 前 に 死ん だ 。',\n",
       " 'その 子 は いつも 何 か <unk> が ある 。',\n",
       " '彼 ら は クラス の クラス に は 全く 我慢 でき なかっ た 。',\n",
       " '私 に あなた に は 何 か でき ます か 。',\n",
       " 'その 老人 は バス から 降り 出し た 。',\n",
       " '人 は いつも 約束 を 守ら なけれ ば なら ない 。',\n",
       " '昨夜 病気 の ため に 彼 は 病気 の ため に 落ち た 。',\n",
       " '私 は 初めて ニューヨーク へ 行っ た 。',\n",
       " '私 は 今 読書 を し て いる 。',\n",
       " '彼 は 以前 は 飲み たく なかっ た 。',\n",
       " '私 は この 部屋 で は とても いい です 。',\n",
       " '健康 ほど 大切 な もの は ない 。',\n",
       " '試験 に 合格 し た の で 試験 に 合格 し た 。',\n",
       " '私 たち は １０ 年間 ずっと 友達 が い ます 。',\n",
       " '彼 は 大学 に 行く の を <unk> て いる 。',\n",
       " '彼 は 試験 に 合格 する こと に 一生 懸命 働い て いる 。',\n",
       " '出 かける 気 に 出 かけ たく ない の です か 。',\n",
       " '彼 は 兄 に 腹 を 立て た 。',\n",
       " '正直 は 結局 <unk> だ 。',\n",
       " '彼 は 試験 に 合格 する こと に 確信 し て いる 。',\n",
       " '子供 たち は ３ つ の 上 に 座っ て い た 。',\n",
       " '私 の 子供 の 世話 を し て 下さい 。',\n",
       " 'それ は 本当 だ と 思う 。',\n",
       " '今 、 仕事 は ほとんど 終わっ た 。',\n",
       " '彼 は 明日 出発 する 。',\n",
       " '私 は 彼 に 本 を あげ た 。',\n",
       " 'それ は 残念 ながら 本当 で は ない 。',\n",
       " 'あなた は 本 を 借り て よい 。',\n",
       " '君 は ボブ の 忠告 を 受け 取っ て は いけ ませ ん 。',\n",
       " '私 たち は 図書 館 に たくさん の 本 が ある 。',\n",
       " 'この 本 は 私 の もの だ 。',\n",
       " '１０ ドル で １０ ドル も 貸し て くれ た 。',\n",
       " 'トム に 会い たい の は トム です 。',\n",
       " 'お 待ち し て き て い ます 。',\n",
       " '妹 さん と 一緒 に 映画 に 行き なさい 。',\n",
       " '彼 ら は 昨夜 恋 を し た 。',\n",
       " '私 は 月 に 母 に 手紙 を 書く つもり は ない 。',\n",
       " '私 は 毎日 走る 。',\n",
       " '時々 子供 の ころ を 見 て いる の が 楽しい 。',\n",
       " '私 は 自分 で 楽しん で 楽しん だ 。',\n",
       " '私 は とても 疲れ て い ます 。',\n",
       " 'アメリカ の 国 は どんな 国 で も 人気 が ある 。',\n",
       " '昨日 あなた に は とても うれしかっ た です 。',\n",
       " '空港 から ホテル まで どの バス が 乗り <unk> です か 。',\n",
       " '私 は あなた より 背 が 高い 。',\n",
       " '子供 たち は 庭 で 遊ぶ 。',\n",
       " '私 は いつも １０ 時 に 寝 ます 。',\n",
       " '宿題 は もう 終わっ た の です か 。',\n",
       " '二人 が あなた に 話し たい の です が 。',\n",
       " '彼 は 家族 の 写真 を 撮っ て あげ た 。',\n",
       " 'その 少年 は １０ 番 が できる 。',\n",
       " '彼 は その 間 ずっと たばこ を やめ た 。',\n",
       " '男の子 は 男の子 の だろう 。',\n",
       " '私 は 最近 仕事 に 早く 帰っ て き た 。',\n",
       " '明日 は 雨 が 降る だろう か 。',\n",
       " 'それ は すぐ に 私 に 知ら せ て ください 。',\n",
       " 'そう いう こと に <unk> な 。',\n",
       " '私 たち は 北海道 に 住ん で いる 。',\n",
       " '私 は 映画 に 行く の が 好き です 。',\n",
       " 'この 本 は 女性 の 中 で とても 人気 が ある 。',\n",
       " '今日 は 勉強 する 必要 は ない 。',\n",
       " 'あなた の 家族 も 幸せ に なっ て い ます 。',\n",
       " '私 は 自分 の 言う こと が わから ない 。',\n",
       " '先生 は 学生 たち に 眠っ た ばかり だ 。',\n",
       " '彼女 は <unk> を 読ん で いる こと を <unk> し て いる 。',\n",
       " '彼 の 計画 は 失敗 に 終わっ た 。',\n",
       " '彼 は 嘘 を つい て い た こと が ある 。',\n",
       " '彼 の 妻 は ２ 、 ２ 、 ３ 年 死ん だ 。',\n",
       " '彼 は 私 と 同じ 辞書 を 持っ て いる 。',\n",
       " '父 は 私 に １００ ドル も 持っ て き た 。',\n",
       " '今日 の 新聞 は 読み まし た か 。',\n",
       " 'その 事実 は 誰 に も 知ら れ て いる 。',\n",
       " '私 は 明日 、 それ を する つもり です 。',\n",
       " '彼 は 助け を 求め て 助け を 求め た 。',\n",
       " '彼女 は 私 に いい こと を 知っ て くれ て くれ 。',\n",
       " '赤ん坊 が 生まれ られる と すぐ に 、 それ は 速く 走れる 。',\n",
       " 'この 問題 に は 全く 仕方 が ない 。',\n",
       " '私 が 宿題 を 終え たら 来る でしょう 。',\n",
       " '私 たち は その ニュース を 聞い て 驚い た 。',\n",
       " '私 は 彼 に 来る こと に なっ て き た 。',\n",
       " '駅 は ホテル の <unk> に あり ます 。',\n",
       " 'ケーキ が 一 つ 一 つ すばらしい 。',\n",
       " '彼 は ニューヨーク へ 行く と すぐ に その 手紙 を やっ た 。',\n",
       " '自転車 は 左側 通行 だ 。',\n",
       " '彼女 は 車 なし で は すまさ れ ない 。',\n",
       " '一目 で 一番 好き な 女性 が 見え まし た 。',\n",
       " '私 は 学生 の 勉強 を 勉強 し て い た もの だっ た 。',\n",
       " '大きな 犬 は いつも 彼 と 同じ 家 に いる 。',\n",
       " '生徒 が 英語 を 先生 に <unk> の を 見 た 。',\n",
       " 'いつ で も 電話 し て ください 。',\n",
       " '私 は 英語 で 日記 を つけ て いる 。',\n",
       " 'ついに 私 の うわさ は 本当 だ 。',\n",
       " 'はい 、 そう です 。',\n",
       " '君 は 早起き だ ね 。',\n",
       " '英語 と 音楽 と 音楽 と は どちら が 好き です か 。',\n",
       " '手 を 洗い なさい 。',\n",
       " '一 年 の 月 は 一 年 の 一 年 です 。',\n",
       " '私 は ２ 年間 住ん で いる 。',\n",
       " 'いい 考え だ よ 。',\n",
       " 'あなた が 英語 の 授業 を 受け て いる そう です ね 。',\n",
       " '私 の 父 は 音楽 が 好き で は ない 。',\n",
       " '彼 は 疲れ て い た とき 、 幸せ に なっ て い た 。',\n",
       " 'それ を 秘密 に し て ください 。',\n",
       " '彼 は 息子 に とっ て すべて を 知っ て いる 。',\n",
       " '少し 休憩 し て ください 。',\n",
       " '彼女 と は 全く 関係 なかっ た 。',\n",
       " '私 は たくさん の お 好き です 。',\n",
       " '私 たち は 毎日 田舎 で 静か に 過ごし た 。',\n",
       " 'ご 親切 に 感謝 し て くれ ます 。',\n",
       " 'クラス の みんな が クラス に 来 た 。',\n",
       " '彼女 は 私 を 聞い て 、 信用 し た こと が 聞こえ ない ふり を し た 。',\n",
       " 'その 結果 は まだ まだ 疑い ある 。',\n",
       " '地球 が 丸い と いう の は 本当 だ 。',\n",
       " '私 は １ 時間 も 友人 を 待っ て い ます 。',\n",
       " '彼 が 試験 に 合格 する つもり だ 。',\n",
       " '彼 に は <unk> し て は いけ ませ ん 。',\n",
       " '家 に 帰っ て き て も いい です か 。',\n",
       " '彼女 の 危険 は 危険 から <unk> て い た 。',\n",
       " '彼 の 町 から 出 かける と 思う 。',\n",
       " '彼女 は 誰 か 話し たい 人 を 言う 。',\n",
       " '息子 は 学校 の 年齢 で は あり ませ ん 。',\n",
       " '今 、 それ は し なけれ ば いけ ませ ん 。',\n",
       " '通り を 渡り なさい 。',\n",
       " '暗い 部屋 で は たくさん の 部屋 を 読む こと は ない 。',\n",
       " '彼 は 自分 の 誤り を おかし た 。',\n",
       " 'あなた の 成功 を 聞い て うれしかっ た 。',\n",
       " 'ペン 貸し て いただけ ませ ん か 。',\n",
       " '電話 を 修理 中 に 修理 し て もらう つもり です 。',\n",
       " '彼女 は パーティー に 出席 し なかっ た 。',\n",
       " '私 は むしろ 行か ない 。',\n",
       " '彼 は 後 に 着い た 。',\n",
       " '彼 の 兄 は とても やさしい 医者 だ 。',\n",
       " 'すぐ に 行か なけれ ば なら ない 。',\n",
       " '私 は 以前 に 会っ た こと が ある 。',\n",
       " '君 は いつも 約束 を 守る 人 だ 。',\n",
       " 'あなた は 何 を 探し て い ます か 。',\n",
       " '彼 の 部屋 は いつも きちんと 整頓 さ れ て いる 。',\n",
       " '彼 は いつも 遅く 来 て い ない 。',\n",
       " '彼女 は もう すっかり <unk> だ 。',\n",
       " '私 は 部屋 に 押し 入っ て 入れ ましょう 。',\n",
       " '彼女 は 子供 の 顔 を 見 ながら 顔 を 見 た 。',\n",
       " '７ 時 です 。',\n",
       " 'その 仕事 に は 我慢 でき ない 。',\n",
       " '風 が <unk> た 。',\n",
       " 'ミルク を ください 。',\n",
       " 'この 車 は 私 の 自由 に 使わ ない 。',\n",
       " '私 は 昨日 、 あなた の 代わり を し て い た 。',\n",
       " 'その 件 に つい て は 、 私 は その 件 に つい て み て み て み ましょう 。',\n",
       " 'その 件 に つい て は 何 も 言わ なかっ た 。',\n",
       " 'コンサート は 本当 に いい の に でし た 。',\n",
       " '箱 を 開け て いただけ ませ ん か 。',\n",
       " '帽子 を 見つけ て しまっ た 。',\n",
       " 'その 映画 は いつ 見 に 出 かけ まし た か 。',\n",
       " '今日 は 私 に 感動 し まし た 。',\n",
       " '私 に は そんな に 金 は 出せ ない 。',\n",
       " '君 は その 男 と 付き 合っ て は いけ ない 。',\n",
       " 'もし 必ず 私 に 電話 し て ください 。',\n",
       " '駅 の 近く に は ちょうど 近い ところ です 。',\n",
       " 'ちょっと 休み を し たら どう し て ください 。',\n",
       " '真実 を 知っ て いる 話 は 本当 に よく 知っ て いる 。',\n",
       " '彼女 は 前日 に 映画 に 行っ た 。',\n",
       " '彼 は 除外 さ れ た 。',\n",
       " 'バス は 混ん で い た 。',\n",
       " '私 たち は 音楽 を 聞い て 楽しん だ 。',\n",
       " '彼 は まだ 元気 が うまい 。',\n",
       " '彼 が 来る こと は 確か だ 。',\n",
       " '「 「 「 「 「 「 「 」 」 」 」 」 」 と 「 「 「 「 「 「 「 「 「 「 「 「 「 「 「 「 「 「 「 「 「 「 「 「 「 「',\n",
       " '彼 は <unk> が 好き だ 。',\n",
       " '若い とき は 若い とき に よく 考え て ください 。',\n",
       " '彼 は 父親 に とっ て <unk> が ある 。',\n",
       " 'あなた の 鉛筆 を 使っ て も いい です か 。',\n",
       " '朝 早く 起き なさい 。',\n",
       " '彼 は ついに 来 た 。',\n",
       " 'あなた は ほとんど 仕事 が あり ます か 。',\n",
       " '私 は 時計 を 修理 し て しまっ た 。',\n",
       " '外国 に 来 て も いい こと は あり ませ ん か 。',\n",
       " '君 は 彼 を 信頼 し て は いけ ない 。',\n",
       " '母 は 買い物 に 出 かけ なかっ た の です か 。',\n",
       " '私 たち は 湖 まで 歩い て 来 た 。',\n",
       " 'とりわけ 、 死ぬ だろう 。',\n",
       " 'すぐ に 失っ た 時間 は あり ませ ん 。',\n",
       " 'それ は 私 に は 何 も 不 自由 な もの で は ない 。',\n",
       " '本当 に お 話し かけ まし た 。',\n",
       " '何時 に 出発 し ます か 。',\n",
       " '後 で 電話 を かけ て ください 。',\n",
       " '彼女 は いつも 母親 の 面倒 を かけ て いる 。',\n",
       " '私 は もう 少し おぼれ た 。',\n",
       " '今年 の 夏 は 楽しい 。',\n",
       " '夏休み 中 から 一 晩 中 寝 て い た 。',\n",
       " '彼 は 私 に とっ て いい 人 だ が 、 彼 は 、 私 に は 、 それ は 、 「 責任 で は 、 「 <unk> ない で は ない で は 、 「 、 「 <unk> ない',\n",
       " '私 は 試験 の 準備 を し て い た 。',\n",
       " '彼女 は 昨日 私 たち に 会い に 来 た 。',\n",
       " 'ここ に は 、 私 たち の １ つ しか 持っ て い ない 。',\n",
       " '彼 は 計画 を 実行 し た 。',\n",
       " 'この 本 は 大 都市 に 入っ て くる 。',\n",
       " '私 は いつも より 遅く 着い た 。',\n",
       " 'これ は あなた の 本 です 。',\n",
       " '私 は 通り で 旧友 に 偶然 出 会っ た 。',\n",
       " '私 は 駅 に 旧友 に 会っ た 。',\n",
       " '彼 は 口 を 消し て も <unk> 。',\n",
       " '彼 は 試験 の 準備 を し なかっ た 。',\n",
       " '私 は たいてい 散歩 し ます 。',\n",
       " '彼女 は 店 で 何 を 買い まし た か 。',\n",
       " '車 で 迎え に 行き なさい 。',\n",
       " '私 の 忠告 を 忠告 し て ください 。',\n",
       " '彼 が 誰 だ か 知っ て いる 。',\n",
       " '彼 は とても 幸せ だっ た よう に 見え た 。',\n",
       " 'コーヒー は 少し も 欲しい 。',\n",
       " '彼女 は たくさん の 料理 が ある 。',\n",
       " 'これ は 人生 に なる 。',\n",
       " 'その 川 は とても <unk> が 見え なかっ た 。',\n",
       " '私 は 彼 と よく バス に 乗っ た 。',\n",
       " 'そんな こと は し ない 方 が いい 。',\n",
       " '彼 は その テスト に 合格 できる よう に 速く 泳げる 。',\n",
       " 'ここ から 駅 まで どの くらい の 距離 です か 。',\n",
       " '大 都市 に は 大 住ん で いる 。',\n",
       " '私 は 彼 の 手 を 手 に 入れ た 。',\n",
       " 'いい 辞書 が 欲しい 。',\n",
       " 'この 本 は 本棚 に 本棚 を 返し なさい 。',\n",
       " 'あなた は 私 が 正しい と 確信 し て いる 。',\n",
       " '出 かける 前 に 火 を 消し なさい 。',\n",
       " 'しばらく 座っ て くれ て 、 注意 し て くれ 。',\n",
       " '英語 は 多く の 人 に よっ て 多く の 人 です 。',\n",
       " '私 は 船 に 乗っ て 船 で 寝 た 。',\n",
       " '今日 は 町 を 見 て いる 。',\n",
       " '彼 は その 問題 を 解く よう に 努力 し た 。',\n",
       " '私 は 白い 部屋 を 書い て ほしい 。',\n",
       " 'その 仕事 は いつも やさしい けれど も 面白い 。',\n",
       " 'そんな こと を 言う な 。',\n",
       " '学ぶ の に 遅 すぎる こと は ない 。',\n",
       " 'あなた の 手紙 に 親切 に なる よ 。',\n",
       " '彼 ら は すばらしい 人 だっ た 。',\n",
       " 'ジェーン は 先週 この 本 を 貸し て くれ ませ ん 。',\n",
       " '彼 の 話 は 誤り で ある と わかっ た 。',\n",
       " '私 は この 本 の ため に この 本 は すまさ れ ない 。',\n",
       " '彼 ら は 動物 園 へ 行っ た 。',\n",
       " '空港 まで 彼 を 見送り に 行っ た 。',\n",
       " '自転車 を 借り て も いい です か 。',\n",
       " 'みんな 君 の <unk> を <unk> て いる 。',\n",
       " '父 は いつも 日曜 日 に いつも 暇 で は ない 。',\n",
       " '私 は 学校 から 帰る 途中 彼 に 会っ た 。',\n",
       " 'あの 子 に は 友だち が ほとんど い ない 。',\n",
       " '暑く なる と <unk> だ 。',\n",
       " 'その 金 は まだ いくら も 使わ ない 。',\n",
       " 'わざわざ 見送り に 来 て くれ て ありがとう 。',\n",
       " '好き な スポーツ は 何 です か 。',\n",
       " '彼 の 言う こと は ある 意味 で ある 。',\n",
       " '夕食 前 に <unk> て くれ ませ ん か 。',\n",
       " '彼 は 私 の 父 です 。',\n",
       " '雨 が やん だ 。',\n",
       " '彼 ら は １ 日 中 働か せ た 。',\n",
       " '私 は 昨日 父 の 手伝い を し た 。',\n",
       " '<unk> は 何 を 言おう と し て いる の 。',\n",
       " '彼 は 禁煙 し た ばかり だ 。',\n",
       " '私 は 難しい 問題 に つい て いる 。',\n",
       " 'これ ら の 絵 は 誰 の もの です か 。',\n",
       " '私 は 地球 を 地球 と 呼ん だ 。',\n",
       " '私 は 今 テニス を し た ところ です 。',\n",
       " '私 は 毎日 毎日 うまく 行っ て き ます 。',\n",
       " '私 が 結婚 し て から ３ 年 に なる 。',\n",
       " '彼 ら は １ 年 中 ずっと ずっと ずっと ずっと ずっと 雨 が 多い 。',\n",
       " '私 は その クラス に <unk> を し て い た 。',\n",
       " '食べ物 を よく 考え て も いい よ 。',\n",
       " '彼 は いつも ７ 時 に 家 に いる 。',\n",
       " 'トム は 彼 の 中 に 寝 て しまっ た 。',\n",
       " '丘 は いつも 青い 。',\n",
       " '学校 に は 何時 に 出 ます か 。',\n",
       " '東京 バス で 行き ます か 。',\n",
       " '犬 と 彼 に 名前 を <unk> て くれ 。',\n",
       " '私 は この 場所 を すぐ に 買っ た 。',\n",
       " '彼 は 勤勉 で ある と 言う 。',\n",
       " 'いつ で も 喜ん で 手伝い ましょう 。',\n",
       " '彼 の 決心 は どう 変え た の かしら 。',\n",
       " 'あなた は ３０ 年 前 に あなた の お 父さん に よく 似 て い た ほう が よく み た ほう が ３０ 年 前 に よく 似 て 、 君 は 、 君 は もう 一度 も 君',\n",
       " 'あなた は 何 で も 好き な もの を 読む 。',\n",
       " '君 は すぐ それ を し た 方 が よい 。',\n",
       " '彼女 の 生徒 は 彼 ら の 目 で 涙 を 見 た 。',\n",
       " '彼 は <unk> の 有名 だ 。',\n",
       " '彼 ら は ジェーン の 名前 を 見 た 。',\n",
       " 'ナンシー が 初めて 来 た 女の子 だっ た 。',\n",
       " 'ビル は 彼 が そんな に 一生 懸命 働い て い た 。',\n",
       " '戦争 が ４ 年 に なる と 戦争 が 起こっ た 。',\n",
       " '雪 が 雪 に 見える 。',\n",
       " '<unk> は 終わっ た 。',\n",
       " '彼女 は 神 を 信じ ない 。',\n",
       " '<unk> は 君 の 金 ほど やさしい 。',\n",
       " 'その 老人 は 、 <unk> の 習慣 を 聞い た 。',\n",
       " 'この 機械 を 洗濯 機 の 使い方 を 教え て ください 。',\n",
       " '車 を 借り て いい です か 。',\n",
       " '１０ 分 で 帰っ て き ます 。',\n",
       " '試合 を やっ て み て ください 。',\n",
       " '彼女 は 自分 の <unk> を 恥じ て いる 。',\n",
       " 'いつ か 私 達 は もう 一度 提案 を 受け たく ない 。',\n",
       " '私 は 少し 英語 を 話し ます 。',\n",
       " '私 に 真実 を 知ら せ て ください 。',\n",
       " '今朝 は いつも より 早く 起き た 。',\n",
       " 'この 大学 に は 数 人 の 学生 が い ない 。',\n",
       " '彼 は その 時 に 楽しん だ 。',\n",
       " '彼 は もう 遅刻 し て しまっ た 。',\n",
       " 'あなた の 中 で も 好き な もの を 選び なさい 。',\n",
       " 'ゴルフ を する の は 楽しい 。',\n",
       " '私 は 父 の 仕事 を 手伝っ た 。',\n",
       " 'あなた から アメリカ から 行っ て いる の は 本当 です 。',\n",
       " '息子 に 何 か 車 で 運転 する 。',\n",
       " '散歩 する の が よい 。',\n",
       " '彼 の 知らせ を 聞い て <unk> た 。',\n",
       " '<unk> は よく 寝 ます 。',\n",
       " 'ちょうど <unk> に 行っ た ところ です 。',\n",
       " 'あなた の 家 は 、 また 近く に い て ね 。',\n",
       " 'あなた は 学校 に 行き ます 。',\n",
       " 'あなた は どこ で も 好き な こと に なっ て いい よ 。',\n",
       " '私 たち は しばしば そこ へ 行き ます 。',\n",
       " '去年 の 冬 は 雪 が よい と 雪 が 多かっ た 。',\n",
       " 'それ は すぐ に <unk> する こと に なる 。',\n",
       " '彼女 は 先生 に なる でしょう 。',\n",
       " '<unk> の うち に は 何 か も 少ない 。',\n",
       " '彼 は 耳 を 信じ られ なかっ た 。',\n",
       " '健康 に は もっと 注意 し なけれ ば いけ ませ ん 。',\n",
       " '彼女 は お 金 を たくさん 持っ て いる 。',\n",
       " '私 は 彼 に 一人 で は でき ない 。',\n",
       " 'その 人 は 多く の 人 に よっ て 多く の 人 が そこ に 行っ た 。',\n",
       " '列車 に 乗り 換え て いけ ませ ん か 。',\n",
       " '雨 が 窓 に <unk> て いる 。',\n",
       " '<unk> は 誰 が アメリカ に いる の です か 。',\n",
       " 'コンピューター を する こと が でき ない 。',\n",
       " '日曜 日 に 会い ましょう 。',\n",
       " 'その 問題 は 決して やさしい 。',\n",
       " '彼 は 不 注意 な の で 私 に は ない よう だ 。',\n",
       " '彼 は 以前 ほど 勤勉 で は ない 。',\n",
       " 'ドア を 開け て は いけ ませ ん 。',\n",
       " '私 は それ を 信じ た の は 本当 だ 。',\n",
       " '返事 を 書い て ください 。',\n",
       " '私 は 次 の 駅 で 降り 出し て き て いる 。',\n",
       " '私 は 兄 を 辞書 を あげ た 。',\n",
       " '彼女 は ちょうど 電話 を かけ た 。',\n",
       " '嵐 の ため 船 は 延期 する こと が 出来 ない だろう 。',\n",
       " 'あなた は 手紙 を 書く べき です か 。',\n",
       " '彼 は 毎朝 ５ 時 まで に 起き ます 。',\n",
       " 'この 痛 み は どう なっ た の です か 。',\n",
       " '空気 が なけれ ば 、 空気 は 何 も ない 。',\n",
       " '私 は 彼 を よい 先生 だ と 考え て いる 。',\n",
       " '私 は 一番 それ を やっ て おき ます 。',\n",
       " 'その 英語 は 彼 ら の <unk> を 知っ て いる 。',\n",
       " '私 たち は 全く 水 が ほしい 。',\n",
       " '私 は 彼 の 忠告 に 従っ た 。',\n",
       " '彼女 が 怒る の は きわめて 当然 だ 。',\n",
       " '我々 は やっと その 問題 に つい て 会議 を 取り 戻し た 。',\n",
       " '私 達 は １ 年 の 最後 に 大変 当惑 し た 。',\n",
       " '彼 ら は 冬 の 間 に 長い 前 だっ た 。',\n",
       " '彼 の 報告 は 本当 の こと を 聞い て は ない 。',\n",
       " 'その 問題 を 解く の が 解け まし た か 。',\n",
       " 'あなた は 行き たい の です か 。',\n",
       " '何 が 心配 です か 。',\n",
       " '火 を 火 に 入れ て ください 。',\n",
       " '木 から 落ち て き た 。',\n",
       " '我々 は その 会合 に 出席 必要 は ない 。',\n",
       " '彼 は 彼女 を 秘書 に し た 。',\n",
       " '彼 は 最近 フランス から 帰っ て き た 。',\n",
       " '東京 は 日本 の 一番 大きい 都市 です 。',\n",
       " '私 は それ を 全部 持っ て い ます 。',\n",
       " 'あなた は <unk> を 見 なさい 。',\n",
       " '会合 は 午後 ３ 時 に 終わっ た 。',\n",
       " '散髪 し て ください 。',\n",
       " 'できる だけ 一生 懸命 やっ て みよう 。',\n",
       " '旅行 に 行き ます 。',\n",
       " '私 は それ を なくし た が それ を 買っ た 。',\n",
       " '私 に つい て すべて の 後 は 読み なさい 。',\n",
       " '彼女 は 彼 に 助け て くれる よう に 頼ん だ 。',\n",
       " '私 は それ を 全て する つもり だ 。',\n",
       " '多く の 人 が 事故 で 死亡 し た 。',\n",
       " '彼 は 今 宿題 を する の に 忙しい 。',\n",
       " '風 が 雪 に なる よう に なっ た 。',\n",
       " 'この 機会 に は <unk> ない よう に 気 を つけ て ください 。',\n",
       " 'その 外国 人 は すぐ に 日本 食 に 慣れ た 。',\n",
       " 'この コート を 着 て あげよう 。',\n",
       " 'その 秘密 は すぐ に <unk> 。',\n",
       " 'よい 部屋 を 持っ て き て ください 。',\n",
       " 'そこ に いく つ か 教え て ください 。',\n",
       " '彼 ら は 私 の <unk> に 反対 し た 。',\n",
       " 'その 船 は ５ 時 まで に ５ 月 に 着く でしょう 。',\n",
       " '新しい 年 が 雪 で <unk> と なっ た 。',\n",
       " '彼 は 私 に アメリカ へ 行く よう に 言っ た 。',\n",
       " '昨夜 彼女 は 風邪 を ひい た 。',\n",
       " 'その 単語 を 辞書 で 調べ なさい 。',\n",
       " '医者 は 病気 の 少年 を <unk> た 。',\n",
       " 'あなた の 薬 は <unk> が でき て い ます 。',\n",
       " '彼 は 昼食 を 食べ まし た か 。',\n",
       " '彼女 は 一 日 中 夫 を 待っ て い た 。',\n",
       " 'この 机 は 由美 は この 机 に 慣れ て いる 。',\n",
       " '彼 の 前 に 部屋 が 立っ て いる 。',\n",
       " '彼 は 列車 に 乗る こと に 乗る こと が できる 。',\n",
       " 'たばこ は 健康 に 悪い 。',\n",
       " '<unk> は 今 家 に い ます か 。',\n",
       " '私 は 彼 と 話 を し て 楽しん だ 。',\n",
       " '私 は 毎年 ここ に 来 なけれ ば なら ない 。',\n",
       " 'あなた に 会え て とても うれしかっ た です 。',\n",
       " '彼 は イギリス へ ２ 回 行っ た こと が ある 。',\n",
       " '仕事 に つい て 、 仕事 を し なさい 。',\n",
       " '私 は よく 風邪 を ひく 。',\n",
       " 'また 来 なさい 。',\n",
       " 'エンジン が 故障 し た 。',\n",
       " '机 の 上 に 本 が あっ た か い 。',\n",
       " '先生 は 私 に 早く 出発 し なかっ た 。',\n",
       " '私 の 家 に 来 て ください 。',\n",
       " '私 は 嘘 を つい た 。',\n",
       " 'テーブル の 上 に 食事 を し て いただけ ませ ん か 。',\n",
       " 'その 計画 は 価値 が ある 。',\n",
       " 'その 少女 は 友人 の こと を 注意 し て み たく なかっ た 。',\n",
       " '自分 で それ は 自分 の 調子 が 悪い 。',\n",
       " '彼女 は 病気 だっ た らしい 。',\n",
       " '彼女 に 会い たい の です が 。',\n",
       " 'その 川 は 以前 より ずっと <unk> が よい 。',\n",
       " 'この 失敗 は 君 の 失敗 の おかげ です 。',\n",
       " '世界 は <unk> もの を やめ なさい 。',\n",
       " '君 は みな 正しい です か 。',\n",
       " '彼 は 自分 の 車 を 持っ て いる 。',\n",
       " '彼 は 試験 に 合格 する こと を 信じ て いる 。',\n",
       " '私 たち は 、 級友 です 。',\n",
       " 'それ は 毎日 やっ て ください 。',\n",
       " 'よく も そんな こと は 言う な 。',\n",
       " '英語 を 歌い ましょう 。',\n",
       " '彼 は いつも の よう に 遅く 着い た 。',\n",
       " '君 は その テレビ を 見 て いる 。',\n",
       " 'それ は 本当 に 聞い て みよう 。',\n",
       " '成功 の 見込み は ほとんど ない 。',\n",
       " '彼 ら に は <unk> が ない 。',\n",
       " '彼女 は とても 親切 です 。',\n",
       " '成功 する と 、 成功 する よ 。',\n",
       " 'バス に 乗り 遅れ た 。',\n",
       " '彼 は ここ に 失望 し て い ます 。',\n",
       " 'どれ くらい かかり ます か 。',\n",
       " '<unk> は どう し た の です か 。',\n",
       " '私 は 彼 が 誰 に か 尋ね た 。',\n",
       " 'この ホテル で は よい か 知っ て い ます か 。',\n",
       " '彼 ら は その こと を まったく <unk> に し なかっ た 。',\n",
       " '人 は 約束 を 守ら なけれ ば なら ない 。',\n",
       " '君 が それ を 知っ て いる の か 。',\n",
       " '彼 を 助け て くれる こと は いけ ない 。',\n",
       " '彼女 は あなた の よい 友達 だ 。',\n",
       " '私 は その よう な 学校 に は いか ない 。',\n",
       " '私 は そんな こと は 少し も 興味 が あり ませ ん 。',\n",
       " '君 が 悪い の は 責任 だ 。',\n",
       " '静か に し て おき なさい 。',\n",
       " '彼 は もう やっ て き た か も しれ ない 。',\n",
       " '私 は 始発 列車 に 乗り たかっ た 。',\n",
       " '彼女 が そう 提案 を 変え た の は とても 意外 だ 。',\n",
       " 'あなた が アメリカ に い た ほう が いい だろう 。',\n",
       " '５ 年 ぶり に 父 は 死ん だ 。',\n",
       " 'その 事故 は 運転 の 運転 の 手 の 中 で 起こっ た 。',\n",
       " '私 は それ を 私 の ため に 読ん だ 。',\n",
       " '多く の 言葉 を 読む こと が 面白い 。',\n",
       " '今夜 は とても 忙しい と 思い ます 。',\n",
       " '父 は 私 の 時間 を <unk> て いる 。',\n",
       " '私 に 部屋 に は 何 か い ます か 。',\n",
       " 'テレビ を 見る 時間 を あまり 楽し み に し ない 。',\n",
       " '家 から 出 かけ た 気分 が 悪い 。',\n",
       " '私 は 彼 の 名前 が 知っ て いる 。',\n",
       " 'ケーキ は 食べ ない で ください 。',\n",
       " '花 は 水 の ため に 死ん だ 。',\n",
       " '彼 は 自分 の こと に つい て やっ て やっ た 。',\n",
       " '彼 は もう これ 以上 働け ない と わかっ た 。',\n",
       " '人前 で 死ん で は 彼 を 口 に し ない 。',\n",
       " '彼 の 責任 は どう も ない 。',\n",
       " '何 も 不 注意 し て い られ ない 。',\n",
       " 'それ は 夢 の よう な 夢 だ 。',\n",
       " '私 は 昨日 の お 金 を もらっ た 。',\n",
       " '彼女 の 息子 は 幸せ な の で ある 。',\n",
       " '車 を 借り て いい です か 。',\n",
       " '病気 だっ た の で 彼 は 学校 へ 行っ た 。',\n",
       " 'ボブ は 朝 早く 彼女 の 朝 早く に 早く 会っ た 。',\n",
       " 'そこ に 出 かけ たら どう 思い 出し て いただけ ます か 。',\n",
       " '彼 は 私 に 何 か 冷たい 飲み物 を くれ た 。',\n",
       " '彼 は きっと 彼 と 同じ だろう 。',\n",
       " '彼 の 命 は 彼女 に 対し て 命 を 得 た 。',\n",
       " '彼 は 英語 を 話す こと が できる 。',\n",
       " '失敗 は 私 に 失敗 し て いつも 失敗 し た 。',\n",
       " 'さあ 、 問題 に は 問題 が ある 。',\n",
       " '妹 は 学校 に 行く の に は 若 すぎる 。',\n",
       " '彼 に とても おもしろい こと を 聞い て とても 面白かっ た 。',\n",
       " '私 は 今日 そこ に 行く 。',\n",
       " '彼 は その 試合 に は 何 も なかっ た 。',\n",
       " '奥さん を 奥さん に し て ください 。',\n",
       " '仕事 を 終え たら 仕事 を し て おき ます 。',\n",
       " 'あなた が 昨日 その 人形 を 買っ て くれ た の か 。',\n",
       " '船 は 川 を 下っ て 川 を 下っ た 。',\n",
       " '子供 の 中 で テレビ が 見え なく て は テレビ を 見 た 。',\n",
       " 'あなた に 話し なさい 。',\n",
       " '彼 の 話 は 気 に 入ら ない 。',\n",
       " '彼女 は 怒っ た の で 私 を 見 た 。',\n",
       " 'その 仕事 は もう 終わっ た 。',\n",
       " '彼 は とても ばか な こと を し た 。',\n",
       " '彼女 は 彼 に 耳 を 傾け た 。',\n",
       " '宗教 を 信じ ない 。',\n",
       " 'なんて すばらしい 日 な こと でしょう 。',\n",
       " '一緒 に 一緒 に 遊ん で くれ ませ ん か 。',\n",
       " '彼 が 間違っ て いる よう だ 。',\n",
       " '彼 は イギリス から 来 ます 。',\n",
       " '日本 は 地震 の 影響 を 受け やすい 。',\n",
       " '手紙 を 書い て ください 。',\n",
       " 'これ は とても 古い 本 です 。',\n",
       " '彼女 は 両親 の <unk> を 受け て い ない 。',\n",
       " 'これ ら の 本 は <unk> です か 。',\n",
       " '彼女 の 息子 は 事故 で 死亡 し た 。',\n",
       " '彼 は 仕事 に 満足 し て いる 。',\n",
       " '私 の 時計 は どこ か 故障 し て いる 。',\n",
       " '家族 に は 何 人 の 家族 が い ます か 。',\n",
       " 'ついに 彼女 は 彼 に 秘密 を つけ た 。',\n",
       " 'どう 思い ます か 。',\n",
       " 'あの 会社 は 今 うまく やっ て き た 。',\n",
       " 'あなた は 何 と お 会い し て うれしい です 。',\n",
       " '私 は １ 週間 で それ を し ます 。',\n",
       " '彼女 は 留学 する こと に 決め た 。',\n",
       " '家 に い て 、 家 に い たい 。',\n",
       " '君 と 僕 も 同じ 年齢 だ 。',\n",
       " '彼 ら は 誰 が 誰 だ か 知っ て い ます か 。',\n",
       " 'もう 彼 に 会っ た こと が あり ます か 。',\n",
       " '君 は 何 を し た の ？',\n",
       " '彼女 は 助け て くれる 必要 が ある 。',\n",
       " '彼女 は 涙 を 涙 で 話し た 。',\n",
       " '空気 が なけれ ば 、 空気 は いけ ない 。',\n",
       " '彼 が 日本 へ 行く の は 本当 だ 。',\n",
       " 'トム は 、 大切 な もの を 書い て くれ た 。',\n",
       " '彼女 は 一度 に 遅刻 し た 。',\n",
       " '娘 は みんな に 行く だろう 。',\n",
       " '昨夜 は よく 眠れ まし た か 。',\n",
       " '私 は 友人 から 手紙 を もらっ た 。',\n",
       " 'ほとんど は ほとんど 授業 に は ほとんど ない 。',\n",
       " 'また 来 なさい 。',\n",
       " 'その 大学 に 入学 し た こと は 彼 の 身 に 入っ た 。',\n",
       " 'バス で 降り ましょう 。',\n",
       " 'その 仕事 は 彼 ら の 重要 だ 。',\n",
       " '彼 ら は <unk> を 降り て き た 。',\n",
       " 'ケン は 助け を 求め て 立ち 寄っ た 。',\n",
       " '彼 は その 時 ここ に い て くれ た 。',\n",
       " '私 は その 公園 で 偶然 <unk> を 見つけ た 。',\n",
       " '私 が 欲しい の は これ だけ です 。',\n",
       " '動物 を <unk> に し て は いけ ませ ん 。',\n",
       " 'ボブ は 戦争 中 に 多く の 間 に 戦争 を 出し た 。',\n",
       " '彼 は 英語 を 大変 上手 に し て いる 。',\n",
       " 'これ は <unk> に たくさん の <unk> を 持っ て いる 。',\n",
       " '私 たち は テニス を し て 楽しん だ 。',\n",
       " '彼女 は その <unk> を 飲み ながら 彼女 は いか なかっ た 。',\n",
       " '日曜 日 に 何 を し ます か 。',\n",
       " 'いい 天気 です ね 。',\n",
       " '彼 は 今晩 疲れ て いる 。',\n",
       " 'これ は 一番 よい もの だ 。',\n",
       " '私 は １ 時間 以上 も 探し て い ない 。',\n",
       " '悪い こと は 考え て み て いただけ ます か 。',\n",
       " '我々 は <unk> の 失敗 を し た こと が でき なかっ た 。',\n",
       " '私 は 悲しい こと に 驚い た 。',\n",
       " '彼 が 自分 で 会っ て も 自分 の 息子 に 会い たい 。',\n",
       " '私 の テレビ は 壊れ た 。',\n",
       " '料理 が 冷え て ます 。',\n",
       " '一番 いい 機会 に お 願い し ます 。',\n",
       " '彼女 は 一 日 中 泣い て ばかり い た 。',\n",
       " '金 は すべて に は もの で は ない 。',\n",
       " '新聞 を 読み 終え たら 読み ましょう 。',\n",
       " '私 たち は 歩き ながら 歌っ た 。',\n",
       " 'もっと 注意 し なさい と 間違い を する よ 。',\n",
       " '君 は 間違っ て いる 。',\n",
       " '私 は 偶然 で 空港 に 会っ た 友達 に 会っ た 。',\n",
       " '彼 は 以前 北海道 に 行っ た こと が ある 。',\n",
       " '仕事 後 は どう し て 仕事 を 飲み に 出 かけ ます か 。',\n",
       " '私 たち は 食べ物 に <unk> に 出 かけ た 。',\n",
       " '父 は 毎日 一生 懸命 働い た 。',\n",
       " 'その 集会 に は 多く の 人 が 出席 し た 。',\n",
       " 'その 母親 は 子供 の 手 に 負え ない 。',\n",
       " '私 の 言う こと は すべて すべて 旨く 行く 。',\n",
       " 'この 絵 を 見 なさい 。',\n",
       " '彼 は 私 たち の 国 で よく 知ら れ て いる 。',\n",
       " '昨日 、 男 が 会い に 来 た 。',\n",
       " '彼 は きっと 来る でしょう 。',\n",
       " '<unk> は 年 に は 古い 。',\n",
       " '英語 は ここ で は 言わ ない 。',\n",
       " '結婚 し て から ２０ 年 に なる 。',\n",
       " '電話 を 使っ て も いい です か 。',\n",
       " '私 は その 知らせ を 聞い て 幸せ でし た 。',\n",
       " '問題 は 実行 する の は どう か だ 。',\n",
       " '彼 は <unk> を 受け た 。',\n",
       " '体 を 大事 に し て ください 。',\n",
       " '彼 は この こと が 全く 好き だ 。',\n",
       " '彼 に は かなり 難しい だろう 。',\n",
       " '勉強 し て は うまく 勉強 し ない か どう か 。',\n",
       " '私 は 名前 が 呼ば れる の が 聞こえ まし た 。',\n",
       " '今日 は 仕事 を 終え た 。',\n",
       " '彼 は アメリカ 人 です か 。',\n",
       " '私 たち は 戦争 を ３ 回 見 た 。',\n",
       " '母 は 子供 たち に 静か に し て くれ た 。',\n",
       " '彼 に 一人 で は いけ ない 。',\n",
       " '私 は 毎日 英語 を 勉強 する 。',\n",
       " '休暇 は どう でし た か 。',\n",
       " '彼女 は 今 腹 を 立てる に は 不 自由 だ 。',\n",
       " '私 は 勉強 する 気 が し ない 。',\n",
       " '<unk> を 起こし ませ ん 。',\n",
       " 'そこ に は たくさん の 人 が い ます 。',\n",
       " 'どちら で も 駅 へ 行く 道 を 行け ば 行き なさい 。',\n",
       " 'コンサート の 切符 を 買っ た こと が あれ ば いい 。',\n",
       " '彼女 は 天使 の よう な 女の子 だ 。',\n",
       " '私 は この 車 に つい て 決め た 。',\n",
       " '私 は とても 熱 が あっ た 。',\n",
       " '風邪 を ひき まし た か 。',\n",
       " '手伝っ て いただけ ませ ん か 。',\n",
       " 'よく 彼女 に なる と 言う の は <unk> です か 。',\n",
       " '彼 は 犬 の 近く に 犬 を 見 た 。',\n",
       " 'あの 女の子 は ジュディ さん の 髪 を 飼っ て いる 。',\n",
       " '最初 彼 ら は いつ 彼 ら に 会い まし た か 。',\n",
       " '彼 は 年 の 割 に は とても 尊敬 し て いる 。',\n",
       " 'なぜ 君 は そんな に 一生 懸命 勉強 し ます か 。',\n",
       " '彼 は ちょうど 学校 に 間に合っ た 。',\n",
       " '彼女 は 失敗 し た 。',\n",
       " '私 は 自分 の 考え を 自分 で 考え て いる 。',\n",
       " '彼 は <unk> だ 。',\n",
       " 'いったい いったい いったい いったい いったい いったい いったい いったい いったい いったい いったい いったい いったい いったい いったい いったい いったい いったい いったい いったい いったい いったい いったい いったい いったい いったい いったい いったい いったい いったい いったい いったい いったい いったい いったい いったい いったい いったい いったい いったい',\n",
       " 'もし あなた が そんな こと を し て 、 どう 思い ます か 。',\n",
       " '彼 の 話 は 信じ られ ます か 。',\n",
       " '通り を 渡っ て いる とき は 注意 し なさい 。',\n",
       " '昨日 は 、 仕事 の 中 で 仕事 が あっ た 。',\n",
       " 'それ は とても いい もの です 。',\n",
       " '川 は <unk> て いる 。',\n",
       " '赤ん坊 は 手 を <unk> た 。',\n",
       " 'この 本 を ３ 年 ３ 年 に 書き まし た 。',\n",
       " '私 は 去年 ほど お 金 が なかっ た 。',\n",
       " 'たばこ を やめ なさい 。 タバコ を やめ なさい 。',\n",
       " '私 は 何 時間 も 働い て 疲れ た 。',\n",
       " '彼 は 、 <unk> を もらっ て いる 。',\n",
       " 'その 女の子 は その 老人 に は あり ませ ん 。',\n",
       " 'あなた は 自転車 に 乗る こと が でき ませ ん か 。',\n",
       " '仕事 を 楽 に し なさい 。',\n",
       " 'それ は あまり に すぎ ます 。',\n",
       " '数 分 いただけ ませ ん か 。',\n",
       " '君 が 正しい と 思う の は 思い ます 。',\n",
       " '彼 は 私 たち に 車 で 招待 さ せ た 。',\n",
       " '実 を 言う と 私 は どう か 真実 です 。',\n",
       " '平和 に は 大切 な もの と は ない 。',\n",
       " '今日 は どう し て いる の です か 。',\n",
       " '質問 し て も いい です か 。',\n",
       " '子供 たち に は 必ず <unk> を 守っ て ください 。',\n",
       " '先日 私 は 旧友 に 会っ た 。',\n",
       " 'その 女性 は とても 美しい 女性 だ 。',\n",
       " '警察 は その 事件 を 調べ て いる ところ です 。',\n",
       " '彼 は 金持ち の 人 の よう に 気 が 見え た 。',\n",
       " 'あなた は １０ 年 年 です か 。',\n",
       " 'ここ に 来 て ください 。',\n",
       " 'あなた は バスケットボール が うまい ？',\n",
       " '来週 仕事 を 出発 する つもり です 。',\n",
       " '私 達 は 毎日 ずっと 年 に なり ます 。',\n",
       " '彼 は 親切 な 人 です 。',\n",
       " 'ここ に 手紙 が あっ て いる の は 、 君 です 。',\n",
       " '庭 の 名前 は すべて 木 に 入っ て もらえ ます か 。',\n",
       " '彼 は 一足 の 靴 を 買っ た 。',\n",
       " 'その 単語 は まず <unk> を 始め て しまっ た 。',\n",
       " '私 は 車 に ひか れ た 。',\n",
       " 'その 火事 は 歴史 に 興味 が ある 。',\n",
       " '私 は あなた と 同様 歌手 で は あり ませ ん 。',\n",
       " '私 は 彼 を 病院 へ 連れ て 行っ た 。',\n",
       " '彼女 は 君 に 毎日 追い つい た 。',\n",
       " '私 の 風邪 を ひい て 寒い より ひどい 目 に かかっ た 。',\n",
       " '最近 彼 が 結婚 し て き た こと は 結局 <unk> だ 。',\n",
       " '誰 も その 真実 を 知っ て い ない よう に 思わ れ た 。',\n",
       " '電話 は 故障 し て いる 。',\n",
       " 'この 机 は <unk> に なっ た 。',\n",
       " 'とても 寒い の で は ない 。',\n",
       " '彼女 は 赤ん坊 を <unk> て しまっ た 。',\n",
       " '彼女 は <unk> で 生まれ た 。',\n",
       " 'これ は 何 の 値段 が 高い です か 。',\n",
       " '誰 も その 答え を 見つけ 出せ なかっ た 。',\n",
       " '道 は どこ で 故障 し て い ます か 。',\n",
       " 'トム は 試合 を <unk> し た 。',\n",
       " '私 は これ 以上 食べ られ ない 。',\n",
       " 'あなた の 妹 は 英語 を 話し ませ ん 。',\n",
       " '嵐 の ため に 何 時間 も 離陸 し なかっ た 。',\n",
       " 'その ホテル は 全く <unk> ない 。',\n",
       " '昨夜 は とても 楽しかっ た 。',\n",
       " '列車 に 乗る と 速く 走り ます 。',\n",
       " '誰 も 自分 の 宿題 を 忘れ た の です か 。',\n",
       " 'どちら の 家 に 住ん で い た の です か 。',\n",
       " '彼女 は もう その 本 を 読み 終え まし た か 。',\n",
       " '<unk> です 。',\n",
       " '彼女 は 美しい こと を <unk> た 。',\n",
       " '彼女 は <unk> に 魚 が 大好き だ 。',\n",
       " '彼 は 暗く なっ て き た 。',\n",
       " '本 を 開け て は いけ ませ ん 。',\n",
       " 'その 橋 は 交通 が 開い て いる 。',\n",
       " 'その 建物 は １ 年 中 終わり ます 。',\n",
       " '今日 は 健康 で ある の で 、 健康 に い た 。',\n",
       " '私 たち は お 金 を <unk> に し なけれ ば なら ない 。',\n",
       " '箱 は 何 と 箱 を 作っ て おき ましょう 。',\n",
       " 'そんな こと を 見 て は いけ ない 。',\n",
       " '何 より も 体 に いい よ 。',\n",
       " '誰 で も それ は 知っ て いる 。',\n",
       " '彼 ら は 大 部分 大 部分 的 な 人 だっ た 。',\n",
       " '私 は トム の 兄 が 若い ころ に 若けれ ば なあ 。',\n",
       " '彼 は 、 ほんの 子供 です 。',\n",
       " 'この 薬 は 私 の 風邪 を 治し た 。',\n",
       " 'あの 少年 たち は なん て きれい な ん だ 。',\n",
       " '私 たち は スキー に スキー に 行き まし た 。',\n",
       " 'ここ に は 数 年 前 に たくさん の 城 が あっ た 。',\n",
       " '今 まで の ところ は 何 も 順調 だ 。',\n",
       " '私 は 彼女 に 本 を 読ん だ こと を 読み まし た 。',\n",
       " 'あなた は 明日 忙しい でしょう 。',\n",
       " '父 は 私 の 友人 と 仲良く やっ て いる 。',\n",
       " '彼 は 先週 町 から 出 て い た 。',\n",
       " 'それ を 頭 に 入れ て ごらん 。',\n",
       " '楽し み に し て も いい です よ 。',\n",
       " '彼 は 親切 だ 。',\n",
       " '彼女 は 私 に もっと 人生 より も 利口 だ 。',\n",
       " '泥棒 は その 金 を <unk> て 逃げ た 。',\n",
       " '私 たち は 誰 で も フランス 人 を 探し て いる 。',\n",
       " '今度 は 早く 来る 。',\n",
       " '昨日 の 帽子 を とても 寒かっ た 。',\n",
       " '人々 は 学ぶ から 経験 を 取り 出し た 。',\n",
       " '明日 は 雨 が 降る でしょう か 。',\n",
       " 'その 結果 は ま も なく 私 たち は よく 知ら ない 。',\n",
       " '私 たち は 火 を 静か に し た 。',\n",
       " '机 の 下 に は 本 が あり ます か 。',\n",
       " '赤ん坊 が 眠っ て しまっ た 。',\n",
       " '彼 は 新しい 車 を 買う 余裕 は ない 。',\n",
       " '誰 で も 、 皆 さん を <unk> て くれ ませ ん か 。',\n",
       " 'その 老人 は 自分 の 帽子 を 見 合っ て い た 。',\n",
       " '父 は 古い 仕事 に は 引き 受け すぎ て い ない 。',\n",
       " '彼 は 妻 の 倍 の 倍 の 大き さ だ 。',\n",
       " '彼 は <unk> 歳 で ２ 年 に なり まし た 。',\n",
       " '数 人 の 人々 は その 講義 に 来 られ ない 。',\n",
       " '結局 は 無駄 だ 。',\n",
       " '昨日 お 金 を 盗ま れ た 。',\n",
       " 'あなた は もう 宿題 を すっかり 終わっ た の です か 。',\n",
       " '芝生 から 立ち 去れ 。',\n",
       " '誰 も 私 を <unk> し て くれ なかっ た 。',\n",
       " '私 は あなた を 誇り に 思っ て いる 。',\n",
       " '私 は この ところ とても 忙しい 。',\n",
       " 'その 答え は 悪い と 思い ませ ん 。',\n",
       " 'あなた は みな 用意 が でき た の です か 。',\n",
       " '<unk> は どの くらい に 出る の か 。',\n",
       " '彼 ら は その 村 に ひどく <unk> て い た 。',\n",
       " '彼女 は 頭 が いい 。',\n",
       " '彼女 は 夕食 後 に <unk> に なっ た 。',\n",
       " '彼 は 警察 に よっ て 警察 官 を 見 られ た 。',\n",
       " '私 達 は 今朝 、 とても 眠い の で 私 たち でし た 。',\n",
       " '彼 の 声 を 聞い て 、 私 は 逃げ た 。',\n",
       " 'あなた は 釣り に 行く べき だ 。',\n",
       " '君 が この 前 に それ を する こと は 難しい 。',\n",
       " '悪い 習慣 は 簡単 に 簡単 に つく こと だ 。',\n",
       " '昨夜 テレビ を 見 まし た か 。',\n",
       " 'これ は あれ より も いい ほう が いい 。',\n",
       " ...]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 出力 ###\n",
    "# 翻訳文に変換して予測結果のリストを作成\n",
    "submission = pd.DataFrame({\"data_id\": data_id_pred, \"pred_target\": output}).sort_values(\"data_id\")\n",
    "submission.to_csv('/root/userspace/submission4_pred1.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
