{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MUWcdth_khfN"
   },
   "source": [
    "# コンペティション課題2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gAjuP7I4lWyn"
   },
   "source": [
    "## 課題\n",
    "\n",
    "CNNを用いて、[Tensorflow Flower Dataset](https://www.tensorflow.org/tutorials/load_data/images)のクラス分類を行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpiz19GRlZ_9"
   },
   "source": [
    "## 目標値\n",
    "\n",
    "Accuracy: 80%  \n",
    "（これはあくまで「目標値」であるため、達成できなかったからといって不合格となったり、著しく成績が損なわれることはありません）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qSHeI_utleEN"
   },
   "source": [
    "## ルール\n",
    "\n",
    "- 「修正しないでください」とあるセルを、修正しないでください。\n",
    "- モデルのアーキテクチャは自由です。講義で扱ったモデル以外でも構いません。\n",
    "- 訓練データはx_train, t_train、テストデータはx_testで与えられます。\n",
    "- 予測ラベルは one_hot表現ではなく0~9のクラスラベルによって表してください。\n",
    "- 以下のセルで定義されているx_train, t_train以外の学習データは使わないでください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "diuec-_YluI6"
   },
   "source": [
    "## 提出方法\n",
    "- 1つのファイルを提出していただきます。\n",
    "  1. テストデータ`test_iter`に対する予測ラベルを`submission1_pred.csv`として保存・ダウンロードし、Homeworkタブから**Day1 Pred (.csv)**を選択して提出してください。\n",
    "  2. それとは別に、最終提出に対応するノートブックをわかるようにiLect上に置いておいてください。\n",
    "\n",
    "\n",
    "- 成績優秀者には、次回講義にて取り組みの発表をお願いいたします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hofSzJsVlvKp"
   },
   "source": [
    "## 評価方法\n",
    "\n",
    "- 予測ラベルのt_testに対する精度 (Accuracy) で評価します。\n",
    "\n",
    "## LeaderBoard\n",
    "\n",
    "- コンペティション期間中のLeaderBoardは提出されたcsvファイルのうち50%を使って計算されます。コンペティション終了時には提出されたcsvファイルのうち、コンペティション期間中のLeaderBoard計算に使われなかったもう半分のデータがスコア計算に使用されます。\n",
    "- このため、コンペ中の順位とコンペ終了後にLeaderBoardが更新された後の順位やスコアが食い違うことがあります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cu4cmQtelx19"
   },
   "source": [
    "## データの読み込み (仮のコード・そもそもtestデータを作っていない）\n",
    "\n",
    "- このセルは修正しないでください。\n",
    "- 誤って修正した場合は、元ファイルをコピーし直してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EsLDDSUJkRx-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class train_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x_train, t_train, transform):\n",
    "        self.x_train = x_train\n",
    "        self.t_train = t_train.astype('int32')\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x_train.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = torch.tensor(self.x_train[idx], dtype=torch.float)\n",
    "        data = torch.transpose(data,0,2)\n",
    "        data = torch.transpose(data,1,2)\n",
    "        label = torch.tensor(self.t_train[idx], dtype=torch.long)\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        return data, label\n",
    "\n",
    "\n",
    "class test_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x_test, transform):\n",
    "        self.x_test = x_test\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x_test.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = torch.tensor(self.x_test[idx], dtype=torch.float)\n",
    "        data = torch.transpose(data,0,2)\n",
    "        data = torch.transpose(data,1,2)\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UrSpHDIWOfK_"
   },
   "source": [
    "### 畳み込みニューラルネットワーク(CNN)の実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla K80\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============NVSMI LOG==============\n",
      "\n",
      "Timestamp                                 : Wed Nov 24 23:17:31 2021\n",
      "Driver Version                            : 450.142.00\n",
      "CUDA Version                              : 11.0\n",
      "\n",
      "Attached GPUs                             : 1\n",
      "GPU 00000000:00:04.0\n",
      "    FB Memory Usage\n",
      "        Total                             : 11441 MiB\n",
      "        Used                              : 3 MiB\n",
      "        Free                              : 11438 MiB\n",
      "    BAR1 Memory Usage\n",
      "        Total                             : 16384 MiB\n",
      "        Used                              : 2 MiB\n",
      "        Free                              : 16382 MiB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -q -d MEMORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f97f77be890>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0) #torchシード固定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adv_inception_v3',\n",
       " 'cait_m36_384',\n",
       " 'cait_m48_448',\n",
       " 'cait_s24_224',\n",
       " 'cait_s24_384',\n",
       " 'cait_s36_384',\n",
       " 'cait_xs24_384',\n",
       " 'cait_xxs24_224',\n",
       " 'cait_xxs24_384',\n",
       " 'cait_xxs36_224',\n",
       " 'cait_xxs36_384',\n",
       " 'coat_lite_mini',\n",
       " 'coat_lite_small',\n",
       " 'coat_lite_tiny',\n",
       " 'coat_mini',\n",
       " 'coat_tiny',\n",
       " 'convit_base',\n",
       " 'convit_small',\n",
       " 'convit_tiny',\n",
       " 'cspdarknet53',\n",
       " 'cspresnet50',\n",
       " 'cspresnext50',\n",
       " 'deit_base_distilled_patch16_224',\n",
       " 'deit_base_distilled_patch16_384',\n",
       " 'deit_base_patch16_224',\n",
       " 'deit_base_patch16_384',\n",
       " 'deit_small_distilled_patch16_224',\n",
       " 'deit_small_patch16_224',\n",
       " 'deit_tiny_distilled_patch16_224',\n",
       " 'deit_tiny_patch16_224',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'densenetblur121d',\n",
       " 'dla34',\n",
       " 'dla46_c',\n",
       " 'dla46x_c',\n",
       " 'dla60',\n",
       " 'dla60_res2net',\n",
       " 'dla60_res2next',\n",
       " 'dla60x',\n",
       " 'dla60x_c',\n",
       " 'dla102',\n",
       " 'dla102x',\n",
       " 'dla102x2',\n",
       " 'dla169',\n",
       " 'dm_nfnet_f0',\n",
       " 'dm_nfnet_f1',\n",
       " 'dm_nfnet_f2',\n",
       " 'dm_nfnet_f3',\n",
       " 'dm_nfnet_f4',\n",
       " 'dm_nfnet_f5',\n",
       " 'dm_nfnet_f6',\n",
       " 'dpn68',\n",
       " 'dpn68b',\n",
       " 'dpn92',\n",
       " 'dpn98',\n",
       " 'dpn107',\n",
       " 'dpn131',\n",
       " 'eca_nfnet_l0',\n",
       " 'eca_nfnet_l1',\n",
       " 'eca_nfnet_l2',\n",
       " 'ecaresnet26t',\n",
       " 'ecaresnet50d',\n",
       " 'ecaresnet50d_pruned',\n",
       " 'ecaresnet50t',\n",
       " 'ecaresnet101d',\n",
       " 'ecaresnet101d_pruned',\n",
       " 'ecaresnet269d',\n",
       " 'ecaresnetlight',\n",
       " 'efficientnet_b0',\n",
       " 'efficientnet_b1',\n",
       " 'efficientnet_b1_pruned',\n",
       " 'efficientnet_b2',\n",
       " 'efficientnet_b2_pruned',\n",
       " 'efficientnet_b3',\n",
       " 'efficientnet_b3_pruned',\n",
       " 'efficientnet_b4',\n",
       " 'efficientnet_el',\n",
       " 'efficientnet_el_pruned',\n",
       " 'efficientnet_em',\n",
       " 'efficientnet_es',\n",
       " 'efficientnet_es_pruned',\n",
       " 'efficientnet_lite0',\n",
       " 'efficientnetv2_rw_m',\n",
       " 'efficientnetv2_rw_s',\n",
       " 'ens_adv_inception_resnet_v2',\n",
       " 'ese_vovnet19b_dw',\n",
       " 'ese_vovnet39b',\n",
       " 'fbnetc_100',\n",
       " 'gernet_l',\n",
       " 'gernet_m',\n",
       " 'gernet_s',\n",
       " 'ghostnet_100',\n",
       " 'gluon_inception_v3',\n",
       " 'gluon_resnet18_v1b',\n",
       " 'gluon_resnet34_v1b',\n",
       " 'gluon_resnet50_v1b',\n",
       " 'gluon_resnet50_v1c',\n",
       " 'gluon_resnet50_v1d',\n",
       " 'gluon_resnet50_v1s',\n",
       " 'gluon_resnet101_v1b',\n",
       " 'gluon_resnet101_v1c',\n",
       " 'gluon_resnet101_v1d',\n",
       " 'gluon_resnet101_v1s',\n",
       " 'gluon_resnet152_v1b',\n",
       " 'gluon_resnet152_v1c',\n",
       " 'gluon_resnet152_v1d',\n",
       " 'gluon_resnet152_v1s',\n",
       " 'gluon_resnext50_32x4d',\n",
       " 'gluon_resnext101_32x4d',\n",
       " 'gluon_resnext101_64x4d',\n",
       " 'gluon_senet154',\n",
       " 'gluon_seresnext50_32x4d',\n",
       " 'gluon_seresnext101_32x4d',\n",
       " 'gluon_seresnext101_64x4d',\n",
       " 'gluon_xception65',\n",
       " 'gmixer_24_224',\n",
       " 'gmlp_s16_224',\n",
       " 'hardcorenas_a',\n",
       " 'hardcorenas_b',\n",
       " 'hardcorenas_c',\n",
       " 'hardcorenas_d',\n",
       " 'hardcorenas_e',\n",
       " 'hardcorenas_f',\n",
       " 'hrnet_w18',\n",
       " 'hrnet_w18_small',\n",
       " 'hrnet_w18_small_v2',\n",
       " 'hrnet_w30',\n",
       " 'hrnet_w32',\n",
       " 'hrnet_w40',\n",
       " 'hrnet_w44',\n",
       " 'hrnet_w48',\n",
       " 'hrnet_w64',\n",
       " 'ig_resnext101_32x8d',\n",
       " 'ig_resnext101_32x16d',\n",
       " 'ig_resnext101_32x32d',\n",
       " 'ig_resnext101_32x48d',\n",
       " 'inception_resnet_v2',\n",
       " 'inception_v3',\n",
       " 'inception_v4',\n",
       " 'legacy_senet154',\n",
       " 'legacy_seresnet18',\n",
       " 'legacy_seresnet34',\n",
       " 'legacy_seresnet50',\n",
       " 'legacy_seresnet101',\n",
       " 'legacy_seresnet152',\n",
       " 'legacy_seresnext26_32x4d',\n",
       " 'legacy_seresnext50_32x4d',\n",
       " 'legacy_seresnext101_32x4d',\n",
       " 'levit_128',\n",
       " 'levit_128s',\n",
       " 'levit_192',\n",
       " 'levit_256',\n",
       " 'levit_384',\n",
       " 'mixer_b16_224',\n",
       " 'mixer_b16_224_in21k',\n",
       " 'mixer_b16_224_miil',\n",
       " 'mixer_b16_224_miil_in21k',\n",
       " 'mixer_l16_224',\n",
       " 'mixer_l16_224_in21k',\n",
       " 'mixnet_l',\n",
       " 'mixnet_m',\n",
       " 'mixnet_s',\n",
       " 'mixnet_xl',\n",
       " 'mnasnet_100',\n",
       " 'mobilenetv2_100',\n",
       " 'mobilenetv2_110d',\n",
       " 'mobilenetv2_120d',\n",
       " 'mobilenetv2_140',\n",
       " 'mobilenetv3_large_100',\n",
       " 'mobilenetv3_large_100_miil',\n",
       " 'mobilenetv3_large_100_miil_in21k',\n",
       " 'mobilenetv3_rw',\n",
       " 'nasnetalarge',\n",
       " 'nf_regnet_b1',\n",
       " 'nf_resnet50',\n",
       " 'nfnet_l0',\n",
       " 'pit_b_224',\n",
       " 'pit_b_distilled_224',\n",
       " 'pit_s_224',\n",
       " 'pit_s_distilled_224',\n",
       " 'pit_ti_224',\n",
       " 'pit_ti_distilled_224',\n",
       " 'pit_xs_224',\n",
       " 'pit_xs_distilled_224',\n",
       " 'pnasnet5large',\n",
       " 'regnetx_002',\n",
       " 'regnetx_004',\n",
       " 'regnetx_006',\n",
       " 'regnetx_008',\n",
       " 'regnetx_016',\n",
       " 'regnetx_032',\n",
       " 'regnetx_040',\n",
       " 'regnetx_064',\n",
       " 'regnetx_080',\n",
       " 'regnetx_120',\n",
       " 'regnetx_160',\n",
       " 'regnetx_320',\n",
       " 'regnety_002',\n",
       " 'regnety_004',\n",
       " 'regnety_006',\n",
       " 'regnety_008',\n",
       " 'regnety_016',\n",
       " 'regnety_032',\n",
       " 'regnety_040',\n",
       " 'regnety_064',\n",
       " 'regnety_080',\n",
       " 'regnety_120',\n",
       " 'regnety_160',\n",
       " 'regnety_320',\n",
       " 'repvgg_a2',\n",
       " 'repvgg_b0',\n",
       " 'repvgg_b1',\n",
       " 'repvgg_b1g4',\n",
       " 'repvgg_b2',\n",
       " 'repvgg_b2g4',\n",
       " 'repvgg_b3',\n",
       " 'repvgg_b3g4',\n",
       " 'res2net50_14w_8s',\n",
       " 'res2net50_26w_4s',\n",
       " 'res2net50_26w_6s',\n",
       " 'res2net50_26w_8s',\n",
       " 'res2net50_48w_2s',\n",
       " 'res2net101_26w_4s',\n",
       " 'res2next50',\n",
       " 'resmlp_12_224',\n",
       " 'resmlp_12_distilled_224',\n",
       " 'resmlp_24_224',\n",
       " 'resmlp_24_distilled_224',\n",
       " 'resmlp_36_224',\n",
       " 'resmlp_36_distilled_224',\n",
       " 'resmlp_big_24_224',\n",
       " 'resmlp_big_24_224_in22ft1k',\n",
       " 'resmlp_big_24_distilled_224',\n",
       " 'resnest14d',\n",
       " 'resnest26d',\n",
       " 'resnest50d',\n",
       " 'resnest50d_1s4x24d',\n",
       " 'resnest50d_4s2x40d',\n",
       " 'resnest101e',\n",
       " 'resnest200e',\n",
       " 'resnest269e',\n",
       " 'resnet18',\n",
       " 'resnet18d',\n",
       " 'resnet26',\n",
       " 'resnet26d',\n",
       " 'resnet34',\n",
       " 'resnet34d',\n",
       " 'resnet50',\n",
       " 'resnet50d',\n",
       " 'resnet51q',\n",
       " 'resnet101d',\n",
       " 'resnet152d',\n",
       " 'resnet200d',\n",
       " 'resnetblur50',\n",
       " 'resnetrs50',\n",
       " 'resnetrs101',\n",
       " 'resnetrs152',\n",
       " 'resnetrs200',\n",
       " 'resnetrs270',\n",
       " 'resnetrs350',\n",
       " 'resnetrs420',\n",
       " 'resnetv2_50x1_bit_distilled',\n",
       " 'resnetv2_50x1_bitm',\n",
       " 'resnetv2_50x1_bitm_in21k',\n",
       " 'resnetv2_50x3_bitm',\n",
       " 'resnetv2_50x3_bitm_in21k',\n",
       " 'resnetv2_101x1_bitm',\n",
       " 'resnetv2_101x1_bitm_in21k',\n",
       " 'resnetv2_101x3_bitm',\n",
       " 'resnetv2_101x3_bitm_in21k',\n",
       " 'resnetv2_152x2_bit_teacher',\n",
       " 'resnetv2_152x2_bit_teacher_384',\n",
       " 'resnetv2_152x2_bitm',\n",
       " 'resnetv2_152x2_bitm_in21k',\n",
       " 'resnetv2_152x4_bitm',\n",
       " 'resnetv2_152x4_bitm_in21k',\n",
       " 'resnext50_32x4d',\n",
       " 'resnext50d_32x4d',\n",
       " 'resnext101_32x8d',\n",
       " 'rexnet_100',\n",
       " 'rexnet_130',\n",
       " 'rexnet_150',\n",
       " 'rexnet_200',\n",
       " 'selecsls42b',\n",
       " 'selecsls60',\n",
       " 'selecsls60b',\n",
       " 'semnasnet_100',\n",
       " 'seresnet50',\n",
       " 'seresnet152d',\n",
       " 'seresnext26d_32x4d',\n",
       " 'seresnext26t_32x4d',\n",
       " 'seresnext50_32x4d',\n",
       " 'skresnet18',\n",
       " 'skresnet34',\n",
       " 'skresnext50_32x4d',\n",
       " 'spnasnet_100',\n",
       " 'ssl_resnet18',\n",
       " 'ssl_resnet50',\n",
       " 'ssl_resnext50_32x4d',\n",
       " 'ssl_resnext101_32x4d',\n",
       " 'ssl_resnext101_32x8d',\n",
       " 'ssl_resnext101_32x16d',\n",
       " 'swin_base_patch4_window7_224',\n",
       " 'swin_base_patch4_window7_224_in22k',\n",
       " 'swin_base_patch4_window12_384',\n",
       " 'swin_base_patch4_window12_384_in22k',\n",
       " 'swin_large_patch4_window7_224',\n",
       " 'swin_large_patch4_window7_224_in22k',\n",
       " 'swin_large_patch4_window12_384',\n",
       " 'swin_large_patch4_window12_384_in22k',\n",
       " 'swin_small_patch4_window7_224',\n",
       " 'swin_tiny_patch4_window7_224',\n",
       " 'swsl_resnet18',\n",
       " 'swsl_resnet50',\n",
       " 'swsl_resnext50_32x4d',\n",
       " 'swsl_resnext101_32x4d',\n",
       " 'swsl_resnext101_32x8d',\n",
       " 'swsl_resnext101_32x16d',\n",
       " 'tf_efficientnet_b0',\n",
       " 'tf_efficientnet_b0_ap',\n",
       " 'tf_efficientnet_b0_ns',\n",
       " 'tf_efficientnet_b1',\n",
       " 'tf_efficientnet_b1_ap',\n",
       " 'tf_efficientnet_b1_ns',\n",
       " 'tf_efficientnet_b2',\n",
       " 'tf_efficientnet_b2_ap',\n",
       " 'tf_efficientnet_b2_ns',\n",
       " 'tf_efficientnet_b3',\n",
       " 'tf_efficientnet_b3_ap',\n",
       " 'tf_efficientnet_b3_ns',\n",
       " 'tf_efficientnet_b4',\n",
       " 'tf_efficientnet_b4_ap',\n",
       " 'tf_efficientnet_b4_ns',\n",
       " 'tf_efficientnet_b5',\n",
       " 'tf_efficientnet_b5_ap',\n",
       " 'tf_efficientnet_b5_ns',\n",
       " 'tf_efficientnet_b6',\n",
       " 'tf_efficientnet_b6_ap',\n",
       " 'tf_efficientnet_b6_ns',\n",
       " 'tf_efficientnet_b7',\n",
       " 'tf_efficientnet_b7_ap',\n",
       " 'tf_efficientnet_b7_ns',\n",
       " 'tf_efficientnet_b8',\n",
       " 'tf_efficientnet_b8_ap',\n",
       " 'tf_efficientnet_cc_b0_4e',\n",
       " 'tf_efficientnet_cc_b0_8e',\n",
       " 'tf_efficientnet_cc_b1_8e',\n",
       " 'tf_efficientnet_el',\n",
       " 'tf_efficientnet_em',\n",
       " 'tf_efficientnet_es',\n",
       " 'tf_efficientnet_l2_ns',\n",
       " 'tf_efficientnet_l2_ns_475',\n",
       " 'tf_efficientnet_lite0',\n",
       " 'tf_efficientnet_lite1',\n",
       " 'tf_efficientnet_lite2',\n",
       " 'tf_efficientnet_lite3',\n",
       " 'tf_efficientnet_lite4',\n",
       " 'tf_efficientnetv2_b0',\n",
       " 'tf_efficientnetv2_b1',\n",
       " 'tf_efficientnetv2_b2',\n",
       " 'tf_efficientnetv2_b3',\n",
       " 'tf_efficientnetv2_l',\n",
       " 'tf_efficientnetv2_l_in21ft1k',\n",
       " 'tf_efficientnetv2_l_in21k',\n",
       " 'tf_efficientnetv2_m',\n",
       " 'tf_efficientnetv2_m_in21ft1k',\n",
       " 'tf_efficientnetv2_m_in21k',\n",
       " 'tf_efficientnetv2_s',\n",
       " 'tf_efficientnetv2_s_in21ft1k',\n",
       " 'tf_efficientnetv2_s_in21k',\n",
       " 'tf_inception_v3',\n",
       " 'tf_mixnet_l',\n",
       " 'tf_mixnet_m',\n",
       " 'tf_mixnet_s',\n",
       " 'tf_mobilenetv3_large_075',\n",
       " 'tf_mobilenetv3_large_100',\n",
       " 'tf_mobilenetv3_large_minimal_100',\n",
       " 'tf_mobilenetv3_small_075',\n",
       " 'tf_mobilenetv3_small_100',\n",
       " 'tf_mobilenetv3_small_minimal_100',\n",
       " 'tnt_s_patch16_224',\n",
       " 'tresnet_l',\n",
       " 'tresnet_l_448',\n",
       " 'tresnet_m',\n",
       " 'tresnet_m_448',\n",
       " 'tresnet_m_miil_in21k',\n",
       " 'tresnet_xl',\n",
       " 'tresnet_xl_448',\n",
       " 'tv_densenet121',\n",
       " 'tv_resnet34',\n",
       " 'tv_resnet50',\n",
       " 'tv_resnet101',\n",
       " 'tv_resnet152',\n",
       " 'tv_resnext50_32x4d',\n",
       " 'twins_pcpvt_base',\n",
       " 'twins_pcpvt_large',\n",
       " 'twins_pcpvt_small',\n",
       " 'twins_svt_base',\n",
       " 'twins_svt_large',\n",
       " 'twins_svt_small',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'visformer_small',\n",
       " 'vit_base_patch16_224',\n",
       " 'vit_base_patch16_224_in21k',\n",
       " 'vit_base_patch16_224_miil',\n",
       " 'vit_base_patch16_224_miil_in21k',\n",
       " 'vit_base_patch16_384',\n",
       " 'vit_base_patch32_224',\n",
       " 'vit_base_patch32_224_in21k',\n",
       " 'vit_base_patch32_384',\n",
       " 'vit_base_r50_s16_224_in21k',\n",
       " 'vit_base_r50_s16_384',\n",
       " 'vit_huge_patch14_224_in21k',\n",
       " 'vit_large_patch16_224',\n",
       " 'vit_large_patch16_224_in21k',\n",
       " 'vit_large_patch16_384',\n",
       " 'vit_large_patch32_224_in21k',\n",
       " 'vit_large_patch32_384',\n",
       " 'vit_large_r50_s32_224',\n",
       " 'vit_large_r50_s32_224_in21k',\n",
       " 'vit_large_r50_s32_384',\n",
       " 'vit_small_patch16_224',\n",
       " 'vit_small_patch16_224_in21k',\n",
       " 'vit_small_patch16_384',\n",
       " 'vit_small_patch32_224',\n",
       " 'vit_small_patch32_224_in21k',\n",
       " 'vit_small_patch32_384',\n",
       " 'vit_small_r26_s32_224',\n",
       " 'vit_small_r26_s32_224_in21k',\n",
       " 'vit_small_r26_s32_384',\n",
       " 'vit_tiny_patch16_224',\n",
       " 'vit_tiny_patch16_224_in21k',\n",
       " 'vit_tiny_patch16_384',\n",
       " 'vit_tiny_r_s16_p8_224',\n",
       " 'vit_tiny_r_s16_p8_224_in21k',\n",
       " 'vit_tiny_r_s16_p8_384',\n",
       " 'wide_resnet50_2',\n",
       " 'wide_resnet101_2',\n",
       " 'xception',\n",
       " 'xception41',\n",
       " 'xception65',\n",
       " 'xception71']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "timm.list_models(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisionTransformer(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "  (blocks): Sequential(\n",
      "    (0): Block(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (2): Block(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (3): Block(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (4): Block(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (5): Block(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (6): Block(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (7): Block(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (8): Block(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (9): Block(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (10): Block(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (11): Block(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "  (pre_logits): Identity()\n",
      "  (head): Linear(in_features=384, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/rwightman/pytorch-image-models/blob/master/results/results-imagenet.csv\n",
    "model_name = 'vit_small_patch16_224'\n",
    "model_tuned = timm.create_model(model_name=model_name,pretrained=True)\n",
    "print(model_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "変更前 :  Linear(in_features=384, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print('変更前 : ', model_tuned.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "変更前 :  Linear(in_features=384, out_features=5, bias=True)\n"
     ]
    }
   ],
   "source": [
    "model_tuned.head = nn.Linear(in_features=384, out_features=5, bias=True)\n",
    "print('変更前 : ', model_tuned.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "  (pre_logits): Identity()\n",
       "  (head): Linear(in_features=384, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.RandomState(1234)\n",
    "random_state = 42\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model_tuned.classifier.apply(init_weights) # 重み・バイアスの初期化を行う\n",
    "model_tuned.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224)\n",
      "(0.5, 0.5, 0.5)\n",
      "(0.5, 0.5, 0.5)\n"
     ]
    }
   ],
   "source": [
    "input_size = timm.get_model_default_value(model_name=model_name,cfg_key=\"input_size\")[1:]\n",
    "Normalize_mean = timm.get_model_default_value(model_name=model_name,cfg_key=\"mean\")\n",
    "Normalize_std = timm.get_model_default_value(model_name=model_name,cfg_key=\"std\")\n",
    "\n",
    "print(input_size)\n",
    "print(Normalize_mean)\n",
    "print(Normalize_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sKAe0F36nSvU"
   },
   "outputs": [],
   "source": [
    "# %%writefile /root/userspace/submission2_code.py\n",
    "# 上記のコメントアウトを外し'%%'以下を実行すると、提出コードが出力できます\n",
    "\n",
    "\n",
    "# 精度向上ポイント: Data Augmentation手法\n",
    "transform_train =  transforms.Compose([])\n",
    "transform_test = transforms.Compose([])\n",
    "\n",
    "# data augmentationとデータ整形\n",
    "\n",
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "         transforms.ToPILImage(),\n",
    "         transforms.RandomHorizontalFlip(p = 0.5),#左右反転\n",
    "         #transforms.RandomVerticalFlip(p=0.5),#上下反転\n",
    "         #transforms.RandomRotation(degrees=30,expand=True),\n",
    "         transforms.Resize(input_size), # 画像によってサイズが変わってはならない。\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize(Normalize_mean, Normalize_std)\n",
    "    ]\n",
    ")\n",
    "transform_test = transforms.Compose(\n",
    "[\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(input_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(Normalize_mean, Normalize_std)\n",
    "]\n",
    ")\n",
    "x_train = np.load('/root/userspace/public/day2/homework2/data/x_train.npy')\n",
    "t_train = np.load('/root/userspace/public/day2/homework2/data/t_train.npy')\n",
    "    \n",
    "# テストデータ\n",
    "x_test = np.load('/root/userspace/public/day2/homework2/data/x_test.npy')\n",
    "\n",
    "trainval_data = train_dataset(x_train, t_train, transform_train)\n",
    "test_data = test_dataset(x_test,transform_test)\n",
    "val_ratio = 0.2\n",
    "val_size = int(len(trainval_data) * val_ratio)\n",
    "train_size = len(trainval_data) - val_size\n",
    "\n",
    "train_data, val_data = torch.utils.data.random_split(trainval_data, [train_size, val_size])\n",
    "\n",
    "# 精度向上ポイント: バッチサイズ\n",
    "batch_size = 32\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "dataloader_valid = torch.utils.data.DataLoader(\n",
    "    val_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "dataloader_test = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wuub_7Sqs_Dm"
   },
   "outputs": [],
   "source": [
    "class GAP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self,x):\n",
    "        return F.adaptive_avg_pool2d(x,(1,1)).squeeze()\n",
    "\n",
    "def init_weights(m):  # Heの初期化\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        torch.nn.init.kaiming_normal_(m.weight)\n",
    "        m.bias.data.fill_(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm #プログレスバー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [01:07<00:00,  1.29it/s]\n",
      "100%|██████████| 22/22 [00:06<00:00,  3.19it/s]\n",
      "  0%|          | 0/87 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0, Train [Loss: 0.283, Accuracy: 0.905], Valid [Loss: 0.097, Accuracy: 0.968]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [01:07<00:00,  1.30it/s]\n",
      "100%|██████████| 22/22 [00:06<00:00,  3.20it/s]\n",
      "  0%|          | 0/87 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1, Train [Loss: 0.058, Accuracy: 0.983], Valid [Loss: 0.082, Accuracy: 0.970]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [01:07<00:00,  1.29it/s]\n",
      "100%|██████████| 22/22 [00:06<00:00,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 2, Train [Loss: 0.026, Accuracy: 0.995], Valid [Loss: 0.084, Accuracy: 0.976]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lr = 0.005\n",
    "optimizer_tuned = optim.SGD(model_tuned.parameters(), lr=lr)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "n_epochs = 3\n",
    "for epoch in range(n_epochs):\n",
    "    losses_train = []\n",
    "    losses_valid = []\n",
    "\n",
    "    model_tuned.train()\n",
    "    n_train = 0\n",
    "    acc_train = 0\n",
    "    for x, t in tqdm(dataloader_train):\n",
    "        n_train += t.size()[0]\n",
    "\n",
    "        model_tuned.zero_grad()  # 勾配の初期化\n",
    "\n",
    "        x = x.to(device)  # テンソルをGPUに移動\n",
    "        t = t.to(device)\n",
    "\n",
    "        y = model_tuned.forward(x)  # 順伝播\n",
    "\n",
    "        loss = loss_function(y, t)  # 誤差(クロスエントロピー誤差関数)の計算\n",
    "\n",
    "        loss.backward()  # 誤差の逆伝播\n",
    "\n",
    "        optimizer_tuned.step()  # パラメータの更新\n",
    "\n",
    "        pred = y.argmax(1)  # 最大値を取るラベルを予測ラベルとする\n",
    "\n",
    "        acc_train += (pred == t).float().sum().item()\n",
    "        losses_train.append(loss.tolist())\n",
    "\n",
    "    model_tuned.eval()\n",
    "    n_val = 0\n",
    "    acc_val = 0\n",
    "    for x, t in tqdm(dataloader_valid):\n",
    "        n_val += t.size()[0]\n",
    "\n",
    "        x = x.to(device)  # テンソルをGPUに移動\n",
    "        t = t.to(device)\n",
    "\n",
    "        y = model_tuned.forward(x)  # 順伝播\n",
    "\n",
    "        loss = loss_function(y, t)  # 誤差(クロスエントロピー誤差関数)の計算\n",
    "\n",
    "        pred = y.argmax(1)  # 最大値を取るラベルを予測ラベルとする\n",
    "\n",
    "        acc_val += (pred == t).float().sum().item()\n",
    "        losses_valid.append(loss.tolist())\n",
    "\n",
    "    print('EPOCH: {}, Train [Loss: {:.3f}, Accuracy: {:.3f}], Valid [Loss: {:.3f}, Accuracy: {:.3f}]'.format(\n",
    "        epoch,\n",
    "        np.mean(losses_train),\n",
    "        acc_train/n_train,\n",
    "        np.mean(losses_valid),\n",
    "        acc_val/n_val\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tuned.to(device)\n",
    "model_tuned.eval()\n",
    "t_pred = []\n",
    "for x in dataloader_test:\n",
    "    x = x.to(device)\n",
    "    output = model_tuned(x)\n",
    "    pred = output.argmax(1).tolist()\n",
    "    t_pred.extend(pred)\n",
    "\n",
    "submission = pd.Series(t_pred, name='label')\n",
    "submission.to_csv('/root/userspace/submission2_pred.csv', header=True, index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      3\n",
       "1      4\n",
       "2      0\n",
       "3      3\n",
       "4      0\n",
       "      ..\n",
       "195    1\n",
       "196    0\n",
       "197    3\n",
       "198    2\n",
       "199    0\n",
       "Name: label, Length: 200, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#検証は水増ししない\n",
    "#git_hubでのランキングを参考に(元画像のサイズ・GPUの性能を参考に)ーバッチサイズも調整（スピード重視のため大きく）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "chap06_homework_pytorch.ipynb ",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
